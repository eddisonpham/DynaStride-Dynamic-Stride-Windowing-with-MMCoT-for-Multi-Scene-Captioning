{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bef4381-f4aa-4d74-a240-b461fe602f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m334.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m272.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m413.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m165.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed hf-xet-1.1.7 huggingface-hub-0.34.4 regex-2025.7.34 safetensors-0.6.2 tokenizers-0.21.4 tqdm-4.67.1 transformers-4.55.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789f59dd-5dff-46f2-b11a-bd475e4bf6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision torchaudio --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fccbbb-b4a3-4bb1-948b-bddd10355618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b260047b35504f5888f6a1a2a35abe5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository DAMO-NLP-SG/VideoLLaMA3-7B contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/DAMO-NLP-SG/VideoLLaMA3-7B .\n",
      " You can inspect the repository content at https://hf.co/DAMO-NLP-SG/VideoLLaMA3-7B.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44195d1dc29c4c65b3e55d120895f49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_videollama3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31245a245ef64360aff25b40ec4e551d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_videollama3_encoder.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/DAMO-NLP-SG/VideoLLaMA3-7B:\n",
      "- configuration_videollama3_encoder.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecfeb801c9264995bcd2f280d3be8c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_videollama3_encoder.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/DAMO-NLP-SG/VideoLLaMA3-7B:\n",
      "- modeling_videollama3_encoder.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/DAMO-NLP-SG/VideoLLaMA3-7B:\n",
      "- configuration_videollama3.py\n",
      "- configuration_videollama3_encoder.py\n",
      "- modeling_videollama3_encoder.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository DAMO-NLP-SG/VideoLLaMA3-7B contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/DAMO-NLP-SG/VideoLLaMA3-7B .\n",
      " You can inspect the repository content at https://hf.co/DAMO-NLP-SG/VideoLLaMA3-7B.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n",
      "The repository DAMO-NLP-SG/VideoLLaMA3-7B contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/DAMO-NLP-SG/VideoLLaMA3-7B .\n",
      " You can inspect the repository content at https://hf.co/DAMO-NLP-SG/VideoLLaMA3-7B.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cf45372f9c4d99bf6f0b1a94d27860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_videollama3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/DAMO-NLP-SG/VideoLLaMA3-7B:\n",
      "- modeling_videollama3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e24607e4b442a08e9508b5bf9e39df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e312e6c9a946e0bfc162e7bc00cde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cb415f2b9f483491e18aada1524a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdf1d4a2dc24b74a283857744455282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133c6b26d27b4075b5ef8d7c90e7f9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.29G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a42316210a34121b823efc920885352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen3-4B-Instruct-2507\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f11681-8583-4079-9a92-99a8a54e56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given multiple captions describing a sequence of actions.\n",
      "Your task is to combine them into ONE concise sentence that is both descriptive and instructional.\n",
      "Use an imperative tone, as if giving step-by-step directions for cooking or performing a task.\n",
      "Keep all actions in logical order and include all relevant details.\n",
      "Your response MUST be strictly in the format:\n",
      "<ANSWER> your one-sentence instruction here </ANSWER>\n",
      "Do NOT add explanations, reasoning, or any text outside the <ANSWER> tags.\n",
      "\n",
      "Captions:\n",
      "1. The sequence of images shows a process of spreading feta and cream cheese on a piece of bread. The process involves using a knife to spread the ingredients, which is done in a step-by- step manner.\n",
      "2. The sequence of images shows a consistent pattern of a woman in a blue shirt, with no changes in her appearance or actions. The sequence is meant to represent a typical scenario of a woman in a blue shirt, without any further details or changes.\n",
      "3. The sequence of images shows a person preparing a sandwich by spreading feta and cream cheese on bread. The sequence is meant to show the steps taken in making this sandwich, which involves spreading the ingredients on the bread.\n",
      "\n",
      "<ANSWER> Take a piece of bread and use a knife to evenly spread feta and cream cheese on both sides. </ANSWER>\n"
     ]
    }
   ],
   "source": [
    "# List of captions from previous sliding-window outputs\n",
    "captions = [\n",
    "    \"The sequence of images shows a process of spreading feta and cream cheese on a piece of bread. The process involves using a knife to spread the ingredients, which is done in a step-by- step manner.\",\n",
    "    \"The sequence of images shows a consistent pattern of a woman in a blue shirt, with no changes in her appearance or actions. The sequence is meant to represent a typical scenario of a woman in a blue shirt, without any further details or changes.\",\n",
    "    \"The sequence of images shows a person preparing a sandwich by spreading feta and cream cheese on bread. The sequence is meant to show the steps taken in making this sandwich, which involves spreading the ingredients on the bread.\"\n",
    "]\n",
    "\n",
    "def build_cooking_summary_prompt(captions):\n",
    "    \"\"\"\n",
    "    Build a prompt that forces the LLM to return exactly one concise\n",
    "    instructional sentence about a cooking task, strictly in <ANSWER> ... </ANSWER>.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are given multiple captions describing a sequence of actions.\\n\"\n",
    "        \"Your task is to combine them into ONE concise sentence that is both descriptive and instructional.\\n\"\n",
    "        \"Use an imperative tone, as if giving step-by-step directions for cooking or performing a task.\\n\"\n",
    "        \"Keep all actions in logical order and include all relevant details.\\n\"\n",
    "        \"Your response MUST be strictly in the format:\\n\"\n",
    "        \"<ANSWER> your one-sentence instruction here </ANSWER>\\n\"\n",
    "        \"Do NOT add explanations, reasoning, or any text outside the <ANSWER> tags.\\n\\n\"\n",
    "        \"Captions:\\n\"\n",
    "    )\n",
    "\n",
    "    # Add captions, skipping 'None'\n",
    "    for i, cap in enumerate(captions, 1):\n",
    "        if cap and cap != \"None\":\n",
    "            prompt += f\"{i}. {cap}\\n\"\n",
    "    \n",
    "    # Close with the opening <ANSWER> tag for generation\n",
    "    prompt += \"\\n<ANSWER>\"\n",
    "    return prompt\n",
    "\n",
    "# Build the prompt\n",
    "prompt = build_cooking_summary_prompt(captions)\n",
    "\n",
    "# Generate the summary\n",
    "outputs = pipe(prompt, max_new_tokens=50, do_sample=True)  # deterministic output\n",
    "\n",
    "# Extract and print strictly the <ANSWER> block\n",
    "final_summary = outputs[0]['generated_text'].strip()\n",
    "\n",
    "print(final_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
