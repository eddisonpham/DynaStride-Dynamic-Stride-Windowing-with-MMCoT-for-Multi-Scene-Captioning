{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9ee64a-85cb-4707-9f26-96118c0056de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.55.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=1.11.0->sentence-transformers) (77.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.7)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=2.0.0->accelerate) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# pipeline_tester.py\n",
    "import os\n",
    "import MMCoT\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from aggregators.aggregator import CookingAggregator  # your modified aggregator\n",
    "\n",
    "# ---------------------------\n",
    "# Install required packages\n",
    "# ---------------------------\n",
    "def install_packages():\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"sentence-transformers\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"accelerate\"])\n",
    "\n",
    "install_packages()\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44d3d2b-33c3-432a-a816-8ff90e0e08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Semantic similarity\n",
    "# ---------------------------\n",
    "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')  # GPU acceleration\n",
    "embedding_cache = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a82d44-0231-4300-bafc-837f44ff2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embedding(text):\n",
    "    if text not in embedding_cache:\n",
    "        vec = semantic_model.encode(text)\n",
    "        embedding_cache[text] = vec / np.linalg.norm(vec)  # pre-normalize\n",
    "    return embedding_cache[text]\n",
    "\n",
    "def semantic_similarity(a, b):\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    vec_a = get_embedding(a)\n",
    "    vec_b = get_embedding(b)\n",
    "    return float(np.dot(vec_a, vec_b))  # fast cosine via dot product\n",
    "\n",
    "# ---------------------------\n",
    "# Frame sampling\n",
    "# ---------------------------\n",
    "def adaptive_frame_sampling(frame_numbers, base_stride=10, frame_frequency=None):\n",
    "    if frame_frequency is not None:\n",
    "        return frame_numbers[::frame_frequency]\n",
    "    return frame_numbers[::base_stride]\n",
    "\n",
    "# ---------------------------\n",
    "# Sliding window captioning\n",
    "# ---------------------------\n",
    "def sliding_window_captioning_dynamic(\n",
    "    folder_path, frame_numbers, processor, model, model_id,\n",
    "    window_size=8, base_stride=8, similarity_threshold=0.70\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates captions for frames using a sliding window approach with dynamic stride adjustment.\n",
    "    Stride increases when consecutive captions are highly similar, decreases otherwise.\n",
    "    \"\"\"\n",
    "    max_stride = base_stride * 3\n",
    "    all_captions = []\n",
    "    prev_caption = None\n",
    "    stride = base_stride\n",
    "    idx = 0\n",
    "    n_frames = len(frame_numbers)\n",
    "\n",
    "    while idx < n_frames:\n",
    "        # Include the last chunk if it overflows\n",
    "        window = frame_numbers[idx:min(idx + window_size, n_frames)]\n",
    "        print(\"Window: \", window)\n",
    "        caption = MMCoT.analyze_sequence_by_indexes(\n",
    "            folder_path,\n",
    "            window,\n",
    "            processor0,\n",
    "            model0,\n",
    "            device=model0.device\n",
    "        )\n",
    "        print(\"Caption:\", caption)\n",
    "\n",
    "        if caption is None or str(caption).strip().lower() == \"none\":\n",
    "            caption = \"\"\n",
    "\n",
    "        # Adjust stride based on similarity\n",
    "        if prev_caption and semantic_similarity(prev_caption, caption) >= similarity_threshold:\n",
    "            stride = min(int(stride * 1.5), max_stride)\n",
    "        else:\n",
    "            if caption.strip():\n",
    "                all_captions.append(caption)\n",
    "                prev_caption = caption\n",
    "            stride = base_stride\n",
    "\n",
    "        idx += max(1, stride)\n",
    "\n",
    "    return all_captions\n",
    "    \n",
    "# ---------------------------\n",
    "# Scene & video processing\n",
    "# ---------------------------\n",
    "def process_scene(\n",
    "    scene_folder, video_folder, processor, model, model_id,\n",
    "    window_size=8, base_stride=8, similarity_threshold=0.7, frame_frequency=5\n",
    "):\n",
    "    scene_path = os.path.join(video_folder, scene_folder)\n",
    "    frame_numbers = sorted(\n",
    "        [f.replace(\"frame_\", \"\").replace(\".jpg\", \"\") for f in os.listdir(scene_path) if f.endswith(\".jpg\")],\n",
    "        key=lambda x: int(x)\n",
    "    )\n",
    "    frame_numbers = [f\"{int(f):04d}\" for f in frame_numbers]\n",
    "\n",
    "    sampled_frames = adaptive_frame_sampling(frame_numbers, base_stride, frame_frequency)\n",
    "\n",
    "    captions = sliding_window_captioning_dynamic(\n",
    "        scene_path, sampled_frames, processor, model, model_id,\n",
    "        window_size=window_size, base_stride=base_stride,\n",
    "        similarity_threshold=similarity_threshold\n",
    "    )\n",
    "\n",
    "    scene_id = int(scene_folder.split(\"_\")[1])  # convert to int for proper ordering\n",
    "    return scene_id, captions\n",
    "\n",
    "def process_video(\n",
    "    video_id, video_folder, processor, model, model_id,\n",
    "    window_size=10, base_stride=10, similarity_threshold=0.70, frame_frequency=10\n",
    "):\n",
    "    scenes = [d for d in os.listdir(video_folder) if os.path.isdir(os.path.join(video_folder, d))]\n",
    "    output = {video_id: {}}\n",
    "    for scene_folder in tqdm(scenes, desc=f\"Processing scenes for {video_id}\"):\n",
    "        scene_id, captions = process_scene(\n",
    "            scene_folder, video_folder, processor, model, model_id,\n",
    "            window_size, base_stride, similarity_threshold, frame_frequency\n",
    "        )\n",
    "        output[video_id][scene_id] = captions\n",
    "    return output\n",
    "\n",
    "# ---------------------------\n",
    "# Ground truth\n",
    "# ---------------------------\n",
    "def get_ground_truth(annotations_file, video_id, scene_count):\n",
    "    with open(annotations_file, \"r\") as f:\n",
    "        annotations_data = json.load(f)\n",
    "\n",
    "    if video_id not in annotations_data[\"database\"]:\n",
    "        print(f\"Warning: {video_id} not found in annotations.\")\n",
    "        return {i: \"\" for i in range(scene_count)}\n",
    "\n",
    "    video_annotations = annotations_data[\"database\"][video_id][\"annotations\"]\n",
    "    ground_truth_dict = {}\n",
    "    for i in range(scene_count):\n",
    "        ground_truth_dict[i] = video_annotations[i][\"sentence\"] if i < len(video_annotations) else \"\"\n",
    "    return ground_truth_dict\n",
    "\n",
    "# ---------------------------\n",
    "# Model Initialization\n",
    "# ---------------------------\n",
    "def initialize_models(aggregator_model, agg_gpu, cot_gpu):\n",
    "    # Load aggregator model\n",
    "    aggregator = CookingAggregator(model_id=aggregator_model, device_index=agg_gpu)\n",
    "\n",
    "    # Load CoT model\n",
    "    device0 = torch.device(f\"cuda:{cot_gpu}\")\n",
    "    processor0, model0 = MMCoT.load_model(model_id=\"Qwen/Qwen2.5-VL-7B-Instruct\", device=device0)\n",
    "    COT_MODEL_ID = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "    return aggregator, processor0, model0, COT_MODEL_ID\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Main Pipeline Aggregation Fix\n",
    "# ---------------------------\n",
    "def run_pipeline(base_folder, sampled_file, output_folder, annotations_file,\n",
    "                 aggregator, processor0, model0, COT_MODEL_ID):\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, \"validation_results.json\")\n",
    "\n",
    "    final_output = {}\n",
    "    if os.path.exists(output_path):\n",
    "        with open(output_path, \"r\") as f:\n",
    "            final_output = json.load(f)\n",
    "        print(f\"Loaded existing JSON with {len(final_output)} videos.\")\n",
    "\n",
    "    with open(sampled_file, \"r\") as f:\n",
    "        all_videos = [line.strip() for line in f if line.strip()]\n",
    "    print(f\"Found {len(all_videos)} sampled videos to process.\")\n",
    "\n",
    "    for video_rel_path in tqdm(all_videos, desc=\"Processing sampled videos\"):\n",
    "        suite_number, video_id = video_rel_path.split(\"/\")\n",
    "        video_folder = os.path.join(base_folder, \"validation\", video_rel_path)\n",
    "\n",
    "        if video_id in final_output:\n",
    "            print(f\"Skipping {video_id}... already exists in JSON.\")\n",
    "            continue\n",
    "        if not os.path.isdir(video_folder):\n",
    "            print(f\"Warning: {video_folder} does not exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Scene captions\n",
    "        video_result = process_video(\n",
    "            video_id, video_folder, processor0, model0, COT_MODEL_ID,\n",
    "            window_size=10, base_stride=10, similarity_threshold=0.50, frame_frequency=10\n",
    "        )\n",
    "\n",
    "        # Aggregation - sort scene_ids numerically to align with ground truth\n",
    "        aggregated_scenes = {}\n",
    "        scene_ids_sorted = sorted(video_result[video_id].keys())\n",
    "        for idx, scene_id in enumerate(scene_ids_sorted):\n",
    "            frame_captions = video_result[video_id][scene_id]\n",
    "            aggregated_scenes[idx] = aggregator.generate_cooking_summary(frame_captions) if frame_captions else \"\"\n",
    "\n",
    "        # Ground truth\n",
    "        scene_count = len(aggregated_scenes)\n",
    "        ground_truth_dict = get_ground_truth(annotations_file, video_id, scene_count)\n",
    "\n",
    "        video_data = {\n",
    "            idx: {\n",
    "                \"ground_truth\": ground_truth_dict.get(idx, \"\"),\n",
    "                \"predicted\": aggregated_scenes.get(idx, \"\")\n",
    "            }\n",
    "            for idx in range(scene_count)\n",
    "        }\n",
    "\n",
    "        # Update JSON\n",
    "        final_output[video_id] = video_data\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(final_output, f, indent=2)\n",
    "\n",
    "        del video_result\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Processed and updated JSON for video: {video_id}\")\n",
    "\n",
    "    print(f\"All results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8e5915-4c1f-4911-bd4e-719e89089976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b702f43f83574f62a4eecf337cc1c651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fa4631853f4b18b71e77c75279f6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Configuration\n",
    "# ---------------------------\n",
    "aggregator_model = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "cot_gpu = 0\n",
    "agg_gpu = 1\n",
    "base_folder = \"/workspace/scene_captioner/data/YouCookII/YouCookII/raw_videos\"\n",
    "sampled_file = \"sampled_videos.txt\"\n",
    "output_folder = \"/workspace/scene_captioner/LLaMACoT/outputs_qwen\"\n",
    "annotations_file = \"/workspace/scene_captioner/data/YouCookII/YouCookII/annotations/youcookii_annotations_trainval.json\"\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Log in to Hugging Face\n",
    "# ---------------------------\n",
    "login(token=\"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\")\n",
    "\n",
    "# ---------------------------\n",
    "# Initialize Models\n",
    "# ---------------------------\n",
    "aggregator, processor0, model0, COT_MODEL_ID = initialize_models(\n",
    "    aggregator_model=aggregator_model,\n",
    "    agg_gpu=agg_gpu,\n",
    "    cot_gpu=cot_gpu\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c05bbc36-106e-4b4e-8ab3-0d4b0e427cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 sampled videos to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sampled videos:   0%|          | 0/210 [00:00<?, ?it/s]\n",
      "Processing scenes for CWxjNRIKjA0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is seasoning food with a pepper grinder. | Pepper grinder, food, kitchen setting</CONCLUSION>\n",
      "Caption: The person is seasoning food with a pepper grinder. | Pepper grinder, food, kitchen setting\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is preparing food in a kitchen setting. | The objects involved include a person, a kitchen counter, a bowl of food, and utensils.</CONCLUSION>\n",
      "Caption: The person is preparing food in a kitchen setting. | The objects involved include a person, a kitchen counter, a bowl of food, and utensils.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for CWxjNRIKjA0:  20%|██        | 1/5 [00:10<00:42, 10.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is stirring a pot of food on the stove with a spoon. | spoon, pot, stove, food, hand</CONCLUSION>\n",
      "Caption: The person is stirring a pot of food on the stove with a spoon. | spoon, pot, stove, food, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is adjusting the lid on a pot containing carrots on a stove. | Pot, lid, stove, carrots, hand</CONCLUSION>\n",
      "Caption: The person is adjusting the lid on a pot containing carrots on a stove. | Pot, lid, stove, carrots, hand\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for CWxjNRIKjA0:  40%|████      | 2/5 [00:26<00:41, 13.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>The person is adjusting the lid on a pot of boiling water containing sweet potatoes. | The objects involved are a pot with sweet potatoes, a lid, a spoon, and a stove.</CONCLUSION>\n",
      "Caption: The person is adjusting the lid on a pot of boiling water containing sweet potatoes. | The objects involved are a pot with sweet potatoes, a lid, a spoon, and a stove.\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding ingredients to a pot | cutting board, spoon, spices, sweet potatoes, red bell peppers, pot, stove, hand</CONCLUSION>\n",
      "Caption: Adding ingredients to a pot | cutting board, spoon, spices, sweet potatoes, red bell peppers, pot, stove, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring vegetables in a pot | pot, stove, spoon, carrots, red bell peppers, hand</CONCLUSION>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for CWxjNRIKjA0:  60%|██████    | 3/5 [00:36<00:23, 11.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: Stirring vegetables in a pot | pot, stove, spoon, carrots, red bell peppers, hand\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Chopping red bell peppers and adding them to sautéed onions in a pot | cutting board, red bell peppers, onions, pot, stove, hand</CONCLUSION>\n",
      "Caption: Chopping red bell peppers and adding them to sautéed onions in a pot | cutting board, red bell peppers, onions, pot, stove, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for CWxjNRIKjA0:  80%|████████  | 4/5 [00:47<00:11, 11.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Adding chopped sweet potatoes into a pot with other vegetables | cutting board, sweet potatoes, pot, stove, hand, knife, vegetables</CONCLUSION>\n",
      "Caption: Adding chopped sweet potatoes into a pot with other vegetables | cutting board, sweet potatoes, pot, stove, hand, knife, vegetables\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Chopping carrots and adding onions into a pot | cutting board, carrots, onions, knife, pot, stove, hand</CONCLUSION>\n",
      "Caption: Chopping carrots and adding onions into a pot | cutting board, carrots, onions, knife, pot, stove, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Chopping vegetables and adding them to a pot | cutting board, knife, chopped vegetables, pot, stove, hand</CONCLUSION>\n",
      "Caption: Chopping vegetables and adding them to a pot | cutting board, knife, chopped vegetables, pot, stove, hand\n",
      "Window:  ['0250', '0260', '0270']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for CWxjNRIKjA0: 100%|██████████| 5/5 [01:00<00:00, 12.09s/it]\u001b[A\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring onions in a pot on the stove | pot, onions, stove, hand, spatula, cutting board, carrots</CONCLUSION>\n",
      "Caption: Stirring onions in a pot on the stove | pot, onions, stove, hand, spatula, cutting board, carrots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is seasoning food with a pepper grinder. | Pepper grinder, food, kitchen setting\\n\\nOutput:\\nGrind pepper into the food while cooking.\\n\\n<ANSWER>\\nGrind pepper into the food while cooking.  \\n</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is stirring a pot of food on the stove with a spoon. | spoon, pot, stove, food, hand\\n\\nOutput:\\nStir the pot of food on the stove with a spoon.  \\n<ANSWER>Stir the food in the pot with a spoon over medium heat.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Adding ingredients to a pot | cutting board, spoon, spices, sweet potatoes, red bell peppers, pot, stove, hand\\n\\nOutput:\\nAdd the sweet potatoes, red bell peppers, and spices to the pot.\\n\\n<ANSWER>Add the sweet potatoes, red bell peppers, and spices to the pot.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Chopping red bell peppers and adding them to sautéed onions in a pot | cutting board, red bell peppers, onions, pot, stove, hand\\n\\nOutput:\\nAdd chopped red bell peppers to the sautéed onions in the pot over medium heat.  \\n<ANSWER>Add chopped red bell peppers to the sautéed onions in the pot over medium heat.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sampled videos:   0%|          | 1/210 [01:06<3:51:27, 66.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Chopping carrots and adding onions into a pot | cutting board, carrots, onions, knife, pot, stove, hand\\n\\nOutput:\\nAdd chopped carrots and onions to the pot. \\n\\n<ANSWER>Add chopped carrots and onions to the pot.</ANSWER>'}]\n",
      "Processed and updated JSON for video: CWxjNRIKjA0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring salad with a spoon | Bowl, salad, spoon, hands</CONCLUSION>\n",
      "Caption: Stirring salad with a spoon | Bowl, salad, spoon, hands\n",
      "Window:  ['0100', '0110', '0120']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY:  11%|█         | 1/9 [00:07<00:59,  7.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring salad with a spoon | bowl, salad, spoon, hands, tablecloth</CONCLUSION>\n",
      "Caption: Stirring salad with a spoon | bowl, salad, spoon, hands, tablecloth\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is adding fresh green lettuce leaves into a bowl containing croutons. | Bowl, croutons, lettuce leaves, hand</CONCLUSION>\n",
      "Caption: The person is adding fresh green lettuce leaves into a bowl containing croutons. | Bowl, croutons, lettuce leaves, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding ingredients to a salad bowl | salad leaves, croutons, cucumber chunks, red onion slices, tomatoes, dressing, small white bowls, large white bowl, hand, wristwatch, tablecloth with herbs pattern</CONCLUSION>\n",
      "Caption: Adding ingredients to a salad bowl | salad leaves, croutons, cucumber chunks, red onion slices, tomatoes, dressing, small white bowls, large white bowl, hand, wristwatch, tablecloth with herbs pattern\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Pouring dressing over salad | Salad, bowl, dressing container, spoon, hand</CONCLUSION>\n",
      "Caption: Pouring dressing over salad | Salad, bowl, dressing container, spoon, hand\n",
      "Window:  ['0350', '0360', '0370', '0380', '0390', '0400']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY:  22%|██▏       | 2/9 [00:27<01:45, 15.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring salad with a spoon | bowl, salad, spoon, person's hand</CONCLUSION>\n",
      "Caption: Stirring salad with a spoon | bowl, salad, spoon, person's hand\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Pouring oil into a ramekin | Ramekin, oil bottle, hand, bowl with sauce, hand, sauce bowl, hand, black liquid bottle, hand</CONCLUSION>\n",
      "Caption: Pouring oil into a ramekin | Ramekin, oil bottle, hand, bowl with sauce, hand, sauce bowl, hand, black liquid bottle, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Pouring dark liquid into a bowl with yellow substance | Bowl, yellow substance, dark liquid, hand, spoon</CONCLUSION>\n",
      "Caption: Pouring dark liquid into a bowl with yellow substance | Bowl, yellow substance, dark liquid, hand, spoon\n",
      "Window:  ['0250', '0260', '0270']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring the mixture in the bowl | Bowl, spoon, liquid, hand</CONCLUSION>\n",
      "Caption: Stirring the mixture in the bowl | Bowl, spoon, liquid, hand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY:  33%|███▎      | 3/9 [00:40<01:25, 14.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Pouring liquid into a bowl | Bowl, cup, liquid, hand</CONCLUSION>\n",
      "Caption: Pouring liquid into a bowl | Bowl, cup, liquid, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is scooping a white substance from a small container into a larger bowl. | The objects involved are a small container with a lid, a white substance, a larger bowl, and a hand.</CONCLUSION>\n",
      "Caption: The person is scooping a white substance from a small container into a larger bowl. | The objects involved are a small container with a lid, a white substance, a larger bowl, and a hand.\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300']\n",
      " addCriterion\n",
      "<CONCLUSION>Whisking mixture in a bowl | whisk, bowl, hand, liquid mixture</CONCLUSION>\n",
      "Caption: Whisking mixture in a bowl | whisk, bowl, hand, liquid mixture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY:  44%|████▍     | 4/9 [00:55<01:11, 14.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is frying triangular pieces of food in a pan with oil. They use a slotted spoon to stir and flip the pieces, ensuring even cooking. The pieces are then transferred to a paper towel-lined plate to absorb excess oil. | Pan, oil, slotted spoon, triangular pieces of food, paper towel-lined plate</CONCLUSION>\n",
      "Caption: The person is frying triangular pieces of food in a pan with oil. They use a slotted spoon to stir and flip the pieces, ensuring even cooking. The pieces are then transferred to a paper towel-lined plate to absorb excess oil. | Pan, oil, slotted spoon, triangular pieces of food, paper towel-lined plate\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Cooking pita bread in oil | pan, oil, pita bread, hand, stove</CONCLUSION>\n",
      "Caption: Cooking pita bread in oil | pan, oil, pita bread, hand, stove\n",
      "Window:  ['0250', '0260', '0270']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring pita bread pieces in a pan with a wooden spoon | pan, wooden spoon, pita bread pieces, stove</CONCLUSION>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY:  56%|█████▌    | 5/9 [01:11<00:59, 14.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: Stirring pita bread pieces in a pan with a wooden spoon | pan, wooden spoon, pita bread pieces, stove\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Placing samosas into hot oil for frying | pan, oil, samosas, cutting board, hand</CONCLUSION>\n",
      "Caption: Placing samosas into hot oil for frying | pan, oil, samosas, cutting board, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Cooking tortilla chips in a pan with oil | pan, tortilla chips, wooden spatula, stove, oil</CONCLUSION>\n",
      "Caption: Cooking tortilla chips in a pan with oil | pan, tortilla chips, wooden spatula, stove, oil\n",
      "Window:  ['0250']\n",
      " addCriterion\n",
      "<CONCLUSION>Cooking pieces of food in a pan with oil | pan, food, oil, stove, hand</CONCLUSION>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY:  67%|██████▋   | 6/9 [01:23<00:42, 14.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: Cooking pieces of food in a pan with oil | pan, food, oil, stove, hand\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding butter and olive oil to a pan | cutting board, knife, chopped bread, butter, olive oil, pan, stove, hand</CONCLUSION>\n",
      "Caption: Adding butter and olive oil to a pan | cutting board, knife, chopped bread, butter, olive oil, pan, stove, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding butter and olive oil to a pan, heating them until they melt and bubble | Butter, Olive Oil, Pan, Stove, Hand</CONCLUSION>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY:  78%|███████▊  | 7/9 [01:34<00:25, 12.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: Adding butter and olive oil to a pan, heating them until they melt and bubble | Butter, Olive Oil, Pan, Stove, Hand\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is cutting a flatbread into smaller pieces using a knife. | Flatbreads, knife, cutting board, hand</CONCLUSION>\n",
      "Caption: The person is cutting a flatbread into smaller pieces using a knife. | Flatbreads, knife, cutting board, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is cutting a large piece of dough into smaller pieces using a knife. | Dough, knife, cutting board</CONCLUSION>\n",
      "Caption: The person is cutting a large piece of dough into smaller pieces using a knife. | Dough, knife, cutting board\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is cutting a large flatbread into smaller pieces using a knife. | Flatbread, knife, cutting board</CONCLUSION>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY:  89%|████████▉ | 8/9 [01:49<00:13, 13.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: The person is cutting a large flatbread into smaller pieces using a knife. | Flatbread, knife, cutting board\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Place sliced red onion into a bowl, then add salt, followed by pepper, and finally herbs.</CONCLUSION>\n",
      "Caption: Place sliced red onion into a bowl, then add salt, followed by pepper, and finally herbs.\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is cracking an egg into a bowl containing sliced red onions and various spices. The egg yolk and white mix with the onions and spices. | Egg, bowl, sliced red onions, spices, hand</CONCLUSION>\n",
      "Caption: The person is cracking an egg into a bowl containing sliced red onions and various spices. The egg yolk and white mix with the onions and spices. | Egg, bowl, sliced red onions, spices, hand\n",
      "Window:  ['0250', '0260', '0270']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for ffhliBglDhY: 100%|██████████| 9/9 [02:03<00:00, 13.74s/it]\u001b[A\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring meat in a bowl | hand, bowl, meat</CONCLUSION>\n",
      "Caption: Stirring meat in a bowl | hand, bowl, meat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Stirring salad with a spoon | Bowl, salad, spoon, hands\\n\\nOutput:\\nStir the salad gently with a spoon.  \\n<ANSWER>Stir the salad gently with a spoon.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is adding fresh green lettuce leaves into a bowl containing croutons. | Bowl, croutons, lettuce leaves, hand\\n2. Pouring dressing over salad | Salad, bowl, dressing container, spoon, hand\\n\\nOutput:\\nAdd dressing to the salad with a spoon. \\n\\n<ANSWER>Add dressing to the salad with a spoon.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Pouring oil into a ramekin | Ramekin, oil bottle, hand, bowl with sauce, hand, sauce bowl, hand, black liquid bottle, hand\\n\\nOutput:\\nAdd oil to the ramekin. \\n\\n<ANSWER>Add oil to the ramekin.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Pouring liquid into a bowl | Bowl, cup, liquid, hand\\n\\nOutput:\\nPour the liquid into the bowl.\\n\\n<ANSWER>\\nPour the liquid into the bowl.  \\n</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is frying triangular pieces of food in a pan with oil. They use a slotted spoon to stir and flip the pieces, ensuring even cooking. The pieces are then transferred to a paper towel-lined plate to absorb excess oil. | Pan, oil, slotted spoon, triangular pieces of food, paper towel-lined plate\\n\\nOutput:\\nFry triangular pieces of food in a pan with oil, using a slotted spoon to flip and stir, then transfer to a paper towel-lined plate to drain excess oil. \\n\\n<ANSWER>\\nFry triangular pieces of food in oil using a slotted spoon to flip and stir, then drain on a paper towel-lined plate. \\n</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Placing samosas into hot oil for frying | pan, oil, samosas, cutting board, hand\\n\\nOutput:\\n<ANSWER> Fry the samosas in hot oil until golden brown. </ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Adding butter and olive oil to a pan | cutting board, knife, chopped bread, butter, olive oil, pan, stove, hand\\n\\nOutput:\\nAdd butter and olive oil to the pan over medium heat. \\n\\n<ANSWER>Add butter and olive oil to the pan over medium heat.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is cutting a flatbread into smaller pieces using a knife. | Flatbreads, knife, cutting board, hand\\n\\nOutput:\\nCut the flatbread into smaller pieces using a knife on a cutting board.\\n\\n<ANSWER>Cut the flatbread into smaller pieces using a knife on a cutting board.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sampled videos:   1%|          | 2/210 [03:20<6:07:22, 105.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Place sliced red onion into a bowl, then add salt, followed by pepper, and finally herbs.\\n2. Stirring meat in a bowl | hand, bowl, meat\\n\\nOutput:\\nAdd salt, pepper, and herbs to sliced red onion, then stir in the meat.  \\n<ANSWER>Combine sliced red onion with salt, pepper, and herbs, then stir in the meat.  \\n</ANSWER>'}]\n",
      "Processed and updated JSON for video: ffhliBglDhY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding sour cream to tacos | tortillas, sour cream, plate, tablecloth</CONCLUSION>\n",
      "Caption: Adding sour cream to tacos | tortillas, sour cream, plate, tablecloth\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:  10%|█         | 1/10 [00:08<01:15,  8.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Adding sour cream to tacos | tortillas, sour cream, coleslaw, plate, tablecloth</CONCLUSION>\n",
      "Caption: Adding sour cream to tacos | tortillas, sour cream, coleslaw, plate, tablecloth\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is slicing meat with a knife while holding it steady with tongs. The meat is placed on a cutting board. | knife, tongs, meat, cutting board</CONCLUSION>\n",
      "Caption: The person is slicing meat with a knife while holding it steady with tongs. The meat is placed on a cutting board. | knife, tongs, meat, cutting board\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Cutting meat with tongs and knife | meat, tongs, knife, cutting board</CONCLUSION>\n",
      "Caption: Cutting meat with tongs and knife | meat, tongs, knife, cutting board\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Chopping meat with a knife | knife, cutting board, meat</CONCLUSION>\n",
      "Caption: Chopping meat with a knife | knife, cutting board, meat\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:  20%|██        | 2/10 [00:29<02:06, 15.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Chopping meat with a knife | knife, cutting board, meat</CONCLUSION>\n",
      "Caption: Chopping meat with a knife | knife, cutting board, meat\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Boiling water in a cast iron skillet | cast iron skillet, stove, water</CONCLUSION>\n",
      "Caption: Boiling water in a cast iron skillet | cast iron skillet, stove, water\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Smoke is rising from the cast iron skillet as it heats up on the stove. | cast iron skillet, stove burner, smoke</CONCLUSION>\n",
      "Caption: Smoke is rising from the cast iron skillet as it heats up on the stove. | cast iron skillet, stove burner, smoke\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>The sequence shows a cast iron skillet being heated on a stovetop burner. The skillet remains stationary throughout the frames, indicating that no cooking is taking place at this moment. | Cast iron skillet, stovetop burner</CONCLUSION>\n",
      "Caption: The sequence shows a cast iron skillet being heated on a stovetop burner. The skillet remains stationary throughout the frames, indicating that no cooking is taking place at this moment. | Cast iron skillet, stovetop burner\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n",
      " addCriterion\n",
      "<CONCLUSION>Cooking steak in a skillet | skillet, steak, stove, burner</CONCLUSION>\n",
      "Caption: Cooking steak in a skillet | skillet, steak, stove, burner\n",
      "Window:  ['0770', '0780', '0790', '0800', '0810', '0820', '0830', '0840', '0850', '0860']\n",
      " addCriterion\n",
      "<CONCLUSION>Steaming steak in a skillet | skillet, steak, stove, plate</CONCLUSION>\n",
      "Caption: Steaming steak in a skillet | skillet, steak, stove, plate\n",
      "Window:  ['1070', '1080', '1090', '1100', '1110', '1120', '1130', '1140', '1150', '1160']\n",
      " addCriterion\n",
      "<CONCLUSION>Flipping the steak with tongs | Steak, tongs, skillet, stove</CONCLUSION>\n",
      "Caption: Flipping the steak with tongs | Steak, tongs, skillet, stove\n",
      "Window:  ['1170', '1180', '1190', '1200', '1210', '1220', '1230', '1240', '1250', '1260']\n",
      " addCriterion\n",
      "<CONCLUSION>Cooking steak in a skillet with tongs | skillet, steak, tongs, stove</CONCLUSION>\n",
      "Caption: Cooking steak in a skillet with tongs | skillet, steak, tongs, stove\n",
      "Window:  ['1320', '1330', '1340', '1350', '1360', '1370', '1380', '1390', '1400', '1410']\n",
      " addCriterion\n",
      "<CONCLUSION>Flipping the steak with tongs | Steak, tongs, cast iron skillet</CONCLUSION>\n",
      "Caption: Flipping the steak with tongs | Steak, tongs, cast iron skillet\n",
      "Window:  ['1540', '1550', '1560', '1570', '1580', '1590', '1600', '1610', '1620', '1630']\n",
      " addCriterion\n",
      "<CONCLUSION>Flipping the steak with tongs | Steak, tongs, frying pan</CONCLUSION>\n",
      "Caption: Flipping the steak with tongs | Steak, tongs, frying pan\n",
      "Window:  ['1840', '1850', '1860', '1870', '1880', '1890', '1900', '1910', '1920', '1930']\n",
      " addCriterion\n",
      "<CONCLUSION>Steak is being seared in a cast iron skillet. | Steak, cast iron skillet, heat source</CONCLUSION>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:  30%|███       | 3/10 [01:22<03:51, 33.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: Steak is being seared in a cast iron skillet. | Steak, cast iron skillet, heat source\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is sealing a plastic bag containing food items. | Plastic bag, food items, hand, measuring cup</CONCLUSION>\n",
      "Caption: The person is sealing a plastic bag containing food items. | Plastic bag, food items, hand, measuring cup\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:  40%|████      | 4/10 [01:32<02:21, 23.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>The person is sealing a plastic bag containing food items. | Plastic bag, food items, hand, kitchen sink, colorful mat</CONCLUSION>\n",
      "Caption: The person is sealing a plastic bag containing food items. | Plastic bag, food items, hand, kitchen sink, colorful mat\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is preparing food by placing ingredients into a plastic bag. | Plastic bag, meat, vegetables, cutting board, hands</CONCLUSION>\n",
      "Caption: The person is preparing food by placing ingredients into a plastic bag. | Plastic bag, meat, vegetables, cutting board, hands\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is opening a plastic bag containing food items. | Plastic bag, food items, hands, table surface</CONCLUSION>\n",
      "Caption: The person is opening a plastic bag containing food items. | Plastic bag, food items, hands, table surface\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is squeezing a yellow object inside a plastic bag, which appears to be a lemon or a similar citrus fruit. The bag is being held over a sink, suggesting that the person might be preparing to juice the fruit. | Lemon, plastic bag, sink, hands, cutting board</CONCLUSION>\n",
      "Caption: The person is squeezing a yellow object inside a plastic bag, which appears to be a lemon or a similar citrus fruit. The bag is being held over a sink, suggesting that the person might be preparing to juice the fruit. | Lemon, plastic bag, sink, hands, cutting board\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:  50%|█████     | 5/10 [01:55<01:56, 23.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>The person is opening a plastic bag containing food items. | Plastic bag, food items, hands, cutting board, sink</CONCLUSION>\n",
      "Caption: The person is opening a plastic bag containing food items. | Plastic bag, food items, hands, cutting board, sink\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Sealing a plastic bag containing food | Plastic bag, food, hands, cutting board, sink</CONCLUSION>\n",
      "Caption: Sealing a plastic bag containing food | Plastic bag, food, hands, cutting board, sink\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Sealing a plastic bag containing food items with a zipper | Plastic bag, zipper, food items, cutting board, measuring cup, kitchen sink</CONCLUSION>\n",
      "Caption: Sealing a plastic bag containing food items with a zipper | Plastic bag, zipper, food items, cutting board, measuring cup, kitchen sink\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Closing a ziplock bag containing food | Ziplock bag, food, cutting board, measuring cup, hands</CONCLUSION>\n",
      "Caption: Closing a ziplock bag containing food | Ziplock bag, food, cutting board, measuring cup, hands\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:  60%|██████    | 6/10 [02:15<01:29, 22.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Seal the bag with a zipper | Zipper, bag, food, cutting board, sink, measuring cup</CONCLUSION>\n",
      "Caption: Seal the bag with a zipper | Zipper, bag, food, cutting board, sink, measuring cup\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Pouring liquid into a blender with fruits and vegetables | blender, fruits, vegetables, measuring cup, cutting board</CONCLUSION>\n",
      "Caption: Pouring liquid into a blender with fruits and vegetables | blender, fruits, vegetables, measuring cup, cutting board\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:  70%|███████   | 7/10 [02:24<00:54, 18.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Pouring liquid into a bag containing chopped vegetables | measuring cup, bag, chopped vegetables, liquid</CONCLUSION>\n",
      "Caption: Pouring liquid into a bag containing chopped vegetables | measuring cup, bag, chopped vegetables, liquid\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Peeling an orange | orange, hand, measuring cup, meat, lime, knife, cutting board</CONCLUSION>\n",
      "Caption: Peeling an orange | orange, hand, measuring cup, meat, lime, knife, cutting board\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Peeling an orange | measuring cup, plastic bag, orange, lime, meat, cutting board, knife</CONCLUSION>\n",
      "Caption: Peeling an orange | measuring cup, plastic bag, orange, lime, meat, cutting board, knife\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Peeling lemons and placing them into a container with other ingredients | lemons, container, meat, onion, lime, knife, hand</CONCLUSION>\n",
      "Caption: Peeling lemons and placing them into a container with other ingredients | lemons, container, meat, onion, lime, knife, hand\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n",
      " addCriterion\n",
      "<CONCLUSION>Peeling lemons into a plastic bag containing other ingredients | Lemons, plastic bag, other ingredients, hand</CONCLUSION>\n",
      "Caption: Peeling lemons into a plastic bag containing other ingredients | Lemons, plastic bag, other ingredients, hand\n",
      "Window:  ['0570', '0580', '0590', '0600', '0610', '0620', '0630', '0640', '0650', '0660']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:  80%|████████  | 8/10 [02:53<00:42, 21.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>The person is preparing a mixture by adding ingredients into a plastic bag. The sequence shows the addition of green limes and yellow fruits, likely jackfruit, into the bag. | Plastic bag, green limes, yellow fruits, measuring cup, cutting board, knife</CONCLUSION>\n",
      "Caption: The person is preparing a mixture by adding ingredients into a plastic bag. The sequence shows the addition of green limes and yellow fruits, likely jackfruit, into the bag. | Plastic bag, green limes, yellow fruits, measuring cup, cutting board, knife\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The hand is seen picking up pieces of meat from a tray, one by one, moving from left to right across the sequence. | Hand, meat, tray</CONCLUSION>\n",
      "Caption: The hand is seen picking up pieces of meat from a tray, one by one, moving from left to right across the sequence. | Hand, meat, tray\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Placing meat into a plastic bag | Meat, plastic bag, measuring cup, vegetables, container</CONCLUSION>\n",
      "Caption: Placing meat into a plastic bag | Meat, plastic bag, measuring cup, vegetables, container\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Placing meat into a bag with marinade | plastic bag, meat, marinade, spoon, cutting board</CONCLUSION>\n",
      "Caption: Placing meat into a bag with marinade | plastic bag, meat, marinade, spoon, cutting board\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is preparing meat for marination. They start by placing pieces of raw meat into a plastic bag. They then use a spoon to add a marinade mixture, which includes visible ingredients like lime slices and possibly other seasonings, into the bag with the meat. The process continues with the person ensuring that the meat is fully coated with the marinade. | meat, plastic bag, spoon, marinade mixture, lime slices, hand</CONCLUSION>\n",
      "Caption: The person is preparing meat for marination. They start by placing pieces of raw meat into a plastic bag. They then use a spoon to add a marinade mixture, which includes visible ingredients like lime slices and possibly other seasonings, into the bag with the meat. The process continues with the person ensuring that the meat is fully coated with the marinade. | meat, plastic bag, spoon, marinade mixture, lime slices, hand\n",
      "Window:  ['0570', '0580', '0590', '0600', '0610', '0620', '0630', '0640', '0650']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE:  90%|█████████ | 9/10 [03:23<00:24, 24.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Placing meat into a bag with marinade | plastic bag, meat, marinade, measuring cup, cutting board, vegetables</CONCLUSION>\n",
      "Caption: Placing meat into a bag with marinade | plastic bag, meat, marinade, measuring cup, cutting board, vegetables\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is picking up and examining pieces of raw meat from a tray. | meat, hand, tray</CONCLUSION>\n",
      "Caption: The person is picking up and examining pieces of raw meat from a tray. | meat, hand, tray\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is holding and examining a piece of raw meat with their hands. The meat is placed on a white tray, and the person's hands move slightly to adjust their grip and position the meat for better inspection. | meat, hand, white tray</CONCLUSION>\n",
      "Caption: The person is holding and examining a piece of raw meat with their hands. The meat is placed on a white tray, and the person's hands move slightly to adjust their grip and position the meat for better inspection. | meat, hand, white tray\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for PHpk4ITk-SE: 100%|██████████| 10/10 [03:41<00:00, 22.10s/it]\u001b[A\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>The person is separating a piece of meat from a larger cut. | Meat, hand, tray</CONCLUSION>\n",
      "Caption: The person is separating a piece of meat from a larger cut. | Meat, hand, tray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Adding sour cream to tacos | tortillas, sour cream, plate, tablecloth\\n\\nOutput:\\nAdd sour cream to the tacos. \\n\\n<ANSWER>Add sour cream to the tacos.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is slicing meat with a knife while holding it steady with tongs. The meat is placed on a cutting board. | knife, tongs, meat, cutting board\\n\\nOutput:\\nSlice the meat using a knife and hold it steady with tongs on a cutting board.\\n\\n<ANSWER>Slice the meat using a knife and hold it steady with tongs on a cutting board.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Boiling water in a cast iron skillet | cast iron skillet, stove, water\\n2. Flipping the steak with tongs | Steak, tongs, skillet, stove\\n\\nOutput:\\nFlip the steak with tongs once the water has boiled. \\n\\n<ANSWER>Flip the steak with tongs once the water has boiled.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is sealing a plastic bag containing food items. | Plastic bag, food items, hand, measuring cup\\n\\nOutput:\\nSeal the plastic bag tightly after placing the food items inside.\\n\\n<ANSWER>Seal the plastic bag tightly after placing the food items inside.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is preparing food by placing ingredients into a plastic bag. | Plastic bag, meat, vegetables, cutting board, hands\\n\\nOutput:\\nPlace the meat and vegetables into the plastic bag. \\n\\n<ANSWER>Place the meat and vegetables into the plastic bag.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Sealing a plastic bag containing food | Plastic bag, food, hands, cutting board, sink\\n\\nOutput:\\nPlace food in a plastic bag and seal it tightly.\\n\\n<ANSWER>Place food in a plastic bag and seal it tightly.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Pouring liquid into a blender with fruits and vegetables | blender, fruits, vegetables, measuring cup, cutting board\\n\\nOutput:\\nAdd fruits and vegetables to the blender with liquid.\\n\\n<ANSWER>Add fruits and vegetables to the blender with liquid.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Peeling an orange | orange, hand, measuring cup, meat, lime, knife, cutting board\\n2. Peeling lemons into a plastic bag containing other ingredients | Lemons, plastic bag, other ingredients, hand\\n\\nOutput:\\nPlace the peeled lemons into the plastic bag with the other ingredients. \\n\\n<ANSWER>Place the peeled lemons into the plastic bag with the other ingredients.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The hand is seen picking up pieces of meat from a tray, one by one, moving from left to right across the sequence. | Hand, meat, tray\\n2. The person is preparing meat for marination. They start by placing pieces of raw meat into a plastic bag. They then use a spoon to add a marinade mixture, which includes visible ingredients like lime slices and possibly other seasonings, into the bag with the meat. The process continues with the person ensuring that the meat is fully coated with the marinade. | meat, plastic bag, spoon, marinade mixture, lime slices, hand\\n\\nOutput:\\nPlace raw meat pieces in a plastic bag and add lime slices and marinade mixture to coat thoroughly. \\n\\n<ANSWER>Place raw meat pieces in a plastic bag and add lime slices and marinade mixture to coat thoroughly.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sampled videos:   1%|▏         | 3/210 [07:12<9:24:44, 163.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is picking up and examining pieces of raw meat from a tray. | meat, hand, tray\\n\\nOutput:\\nTake the raw meat pieces from the tray and place them on a cutting board.\\n\\n<ANSWER>Take the raw meat pieces from the tray and place them on a cutting board.</ANSWER>'}]\n",
      "Processed and updated JSON for video: PHpk4ITk-SE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for HF49t8uVJOE:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>She is reading a recipe card while holding a spoon and stirring something in a pot. | Recipe card, spoon, pot, kitchen counter, cabinets, knives, pots and pans, plants, countertop.</CONCLUSION>\n",
      "Caption: She is reading a recipe card while holding a spoon and stirring something in a pot. | Recipe card, spoon, pot, kitchen counter, cabinets, knives, pots and pans, plants, countertop.\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The woman is placing a lemon into a pot of boiling water. | lemon, pot, boiling water, paper towel</CONCLUSION>\n",
      "Caption: The woman is placing a lemon into a pot of boiling water. | lemon, pot, boiling water, paper towel\n",
      "Window:  ['0200', '0210', '0220', '0230', '0240', '0250', '0260', '0270', '0280', '0290']\n",
      " addCriterion\n",
      "<CONCLUSION>The woman is placing a piece of paper into a steamer basket inside a pot. | Objects involved: woman, blue apron, paper, steamer basket, pot, kitchen counter, cabinets, tiled backsplash, knife block, pots and pans, cutting board.</CONCLUSION>\n",
      "Caption: The woman is placing a piece of paper into a steamer basket inside a pot. | Objects involved: woman, blue apron, paper, steamer basket, pot, kitchen counter, cabinets, tiled backsplash, knife block, pots and pans, cutting board.\n",
      "Window:  ['0350', '0360', '0370', '0380', '0390', '0400', '0410', '0420', '0430', '0440']\n",
      " addCriterion\n",
      "<CONCLUSION>The woman is scooping food from a pot into a plate. | Objects: woman, pot, spoon, plate, food</CONCLUSION>\n",
      "Caption: The woman is scooping food from a pot into a plate. | Objects: woman, pot, spoon, plate, food\n",
      "Window:  ['0450', '0460', '0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540']\n",
      " addCriterion\n",
      "<CONCLUSION>The woman is transferring food from a plate to a steamer basket. | Objects involved: woman, blue apron, plate with food, steamer basket, kitchen counter, cabinets, knives, pots, and pans.</CONCLUSION>\n",
      "Caption: The woman is transferring food from a plate to a steamer basket. | Objects involved: woman, blue apron, plate with food, steamer basket, kitchen counter, cabinets, knives, pots, and pans.\n",
      "Window:  ['0600', '0610', '0620', '0630', '0640', '0650', '0660']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is transferring fried food from a pot to a paper towel-lined plate using tongs. | Pot, tongs, fried food, paper towel-lined plate, person's hands</CONCLUSION>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for HF49t8uVJOE:  17%|█▋        | 1/6 [00:35<02:57, 35.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: The person is transferring fried food from a pot to a paper towel-lined plate using tongs. | Pot, tongs, fried food, paper towel-lined plate, person's hands\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The woman is transferring something from one pot to another using a utensil. | Pots, utensil, woman, apron, kitchen background</CONCLUSION>\n",
      "Caption: The woman is transferring something from one pot to another using a utensil. | Pots, utensil, woman, apron, kitchen background\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The woman is transferring something from one pot to another using a utensil. | Pots, utensil, woman, kitchen background</CONCLUSION>\n",
      "Caption: The woman is transferring something from one pot to another using a utensil. | Pots, utensil, woman, kitchen background\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for HF49t8uVJOE:  33%|███▎      | 2/6 [00:51<01:35, 23.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>She is stirring the contents of a pot with a spoon. | Pot, spoon, woman, kitchen counter, cabinets, countertop items</CONCLUSION>\n",
      "Caption: She is stirring the contents of a pot with a spoon. | Pot, spoon, woman, kitchen counter, cabinets, countertop items\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>She is mixing ingredients in a bowl with a spoon. | Bowl, spoon, ingredients, woman, kitchen counter, pots, cabinets, knife block, plants.</CONCLUSION>\n",
      "Caption: She is mixing ingredients in a bowl with a spoon. | Bowl, spoon, ingredients, woman, kitchen counter, pots, cabinets, knife block, plants.\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>She is mixing ingredients in a bowl with a spoon. | Bowl, spoon, ingredients, woman, kitchen counter, pots, papers</CONCLUSION>\n",
      "Caption: She is mixing ingredients in a bowl with a spoon. | Bowl, spoon, ingredients, woman, kitchen counter, pots, papers\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for HF49t8uVJOE:  50%|█████     | 3/6 [01:06<00:59, 19.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>She is mixing ingredients in a bowl with a spoon. | Bowl, spoon, ingredients, kitchen counter, cabinets, pots, papers</CONCLUSION>\n",
      "Caption: She is mixing ingredients in a bowl with a spoon. | Bowl, spoon, ingredients, kitchen counter, cabinets, pots, papers\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>She is pouring liquid from one pot into another. | Pots, spoons, woman, kitchen background</CONCLUSION>\n",
      "Caption: She is pouring liquid from one pot into another. | Pots, spoons, woman, kitchen background\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>She is mixing ingredients in a bowl with a whisk. | Bowl, whisk, ingredients, woman, kitchen counter, cabinets, sink, utensils, pots, stove, countertop.</CONCLUSION>\n",
      "Caption: She is mixing ingredients in a bowl with a whisk. | Bowl, whisk, ingredients, woman, kitchen counter, cabinets, sink, utensils, pots, stove, countertop.\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for HF49t8uVJOE:  67%|██████▋   | 4/6 [01:21<00:35, 17.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>She is pouring liquid from one pot into another.| Pots, bowls, measuring cups, kitchen utensils, woman's apron</CONCLUSION>\n",
      "Caption: She is pouring liquid from one pot into another.| Pots, bowls, measuring cups, kitchen utensils, woman's apron\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>She is stirring a pot with a spoon | Pots, spoons, kitchen, woman, apron</CONCLUSION>\n",
      "Caption: She is stirring a pot with a spoon | Pots, spoons, kitchen, woman, apron\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>She is pouring a liquid from a measuring cup into a pot on the stove. | Pots, measuring cups, stove, countertop, kitchenware, woman, apron</CONCLUSION>\n",
      "Caption: She is pouring a liquid from a measuring cup into a pot on the stove. | Pots, measuring cups, stove, countertop, kitchenware, woman, apron\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for HF49t8uVJOE:  83%|████████▎ | 5/6 [01:38<00:17, 17.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>The woman is lifting a metal mixing bowl from a counter. | Metal mixing bowls, kitchen counter, cabinets, utensils, apron.</CONCLUSION>\n",
      "Caption: The woman is lifting a metal mixing bowl from a counter. | Metal mixing bowls, kitchen counter, cabinets, utensils, apron.\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>She is preparing food in a kitchen setting. | apron, woman, pots, utensils, kitchen counter, cabinets, sink, plants, tiled backsplash</CONCLUSION>\n",
      "Caption: She is preparing food in a kitchen setting. | apron, woman, pots, utensils, kitchen counter, cabinets, sink, plants, tiled backsplash\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>She is preparing food in the kitchen. | pots, bowls, utensils, woman, kitchen counter, cabinets, sink, plants</CONCLUSION>\n",
      "Caption: She is preparing food in the kitchen. | pots, bowls, utensils, woman, kitchen counter, cabinets, sink, plants\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for HF49t8uVJOE: 100%|██████████| 6/6 [01:54<00:00, 19.10s/it]\u001b[A\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>She is pouring something from one pot into another. | Pots, woman, apron, kitchen counter, sink, cabinets, utensils</CONCLUSION>\n",
      "Caption: She is pouring something from one pot into another. | Pots, woman, apron, kitchen counter, sink, cabinets, utensils\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. She is reading a recipe card while holding a spoon and stirring something in a pot. | Recipe card, spoon, pot, kitchen counter, cabinets, knives, pots and pans, plants, countertop.\\n2. The woman is placing a lemon into a pot of boiling water. | lemon, pot, boiling water, paper towel\\n3. The woman is scooping food from a pot into a plate. | Objects: woman, pot, spoon, plate, food\\n\\nOutput:\\nAdd a lemon to the boiling water. \\n\\n<ANSWER>Add a lemon to the boiling water.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The woman is transferring something from one pot to another using a utensil. | Pots, utensil, woman, apron, kitchen background\\n\\nOutput:\\nTransfer the contents from one pot to another using a spoon.\\n\\n<ANSWER>Transfer the contents from one pot to another using a spoon.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. She is mixing ingredients in a bowl with a spoon. | Bowl, spoon, ingredients, woman, kitchen counter, pots, cabinets, knife block, plants.\\n\\nOutput:\\nMix the ingredients together in the bowl using a spoon.\\n\\n<ANSWER>Mix the ingredients together in the bowl using a spoon.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. She is pouring liquid from one pot into another. | Pots, spoons, woman, kitchen background\\n\\nOutput:\\nPour the liquid from one pot to another.\\n\\n<ANSWER>\\nPour the liquid from one pot to another.  \\n</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. She is stirring a pot with a spoon | Pots, spoons, kitchen, woman, apron\\n\\nOutput:\\nStir the pot continuously with a spoon.  \\n<ANSWER>Stir the pot constantly with a spoon. </ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sampled videos:   2%|▏         | 4/210 [09:12<8:22:59, 146.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. She is preparing food in a kitchen setting. | apron, woman, pots, utensils, kitchen counter, cabinets, sink, plants, tiled backsplash\\n\\nOutput:\\nPlace the ingredients in a pot and bring to a boil.\\n\\n<ANSWER>Place the ingredients in a pot and bring to a boil.</ANSWER>'}]\n",
      "Processed and updated JSON for video: HF49t8uVJOE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for 5VnaolWGIy4:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring pasta salad with a spoon | Bowl, pasta salad, wooden cutting board, green leafy vegetables, hand</CONCLUSION>\n",
      "Caption: Stirring pasta salad with a spoon | Bowl, pasta salad, wooden cutting board, green leafy vegetables, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding kale to pasta salad | bowl, pasta salad, kale, wooden cutting board, hand</CONCLUSION>\n",
      "Caption: Adding kale to pasta salad | bowl, pasta salad, kale, wooden cutting board, hand\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring salad with a spatula | Bowl, salad, spatula, wooden spoon, greens, tomatoes, olives, pasta</CONCLUSION>\n",
      "Caption: Stirring salad with a spatula | Bowl, salad, spatula, wooden spoon, greens, tomatoes, olives, pasta\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for 5VnaolWGIy4:  20%|██        | 1/5 [00:21<01:25, 21.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring pasta salad with a spatula | Bowl, pasta salad, spatula, wooden surface, herbs</CONCLUSION>\n",
      "Caption: Stirring pasta salad with a spatula | Bowl, pasta salad, spatula, wooden surface, herbs\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding diced tomatoes to pasta | bowl, pasta, diced tomatoes, red spatula</CONCLUSION>\n",
      "Caption: Adding diced tomatoes to pasta | bowl, pasta, diced tomatoes, red spatula\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding ingredients to pasta salad | pasta, red bell peppers, black olives, mixing spoon, glass bowl</CONCLUSION>\n",
      "Caption: Adding ingredients to pasta salad | pasta, red bell peppers, black olives, mixing spoon, glass bowl\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring pasta salad with a spoon | Bowl, pasta, vegetables, spoon, hand</CONCLUSION>\n",
      "Caption: Stirring pasta salad with a spoon | Bowl, pasta, vegetables, spoon, hand\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring pasta with a spatula | Bowl, pasta, spatula, hand</CONCLUSION>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for 5VnaolWGIy4:  40%|████      | 2/5 [00:40<01:00, 20.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: Stirring pasta with a spatula | Bowl, pasta, spatula, hand\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding bacon to pasta | bowl, pasta, bacon, spatula</CONCLUSION>\n",
      "Caption: Adding bacon to pasta | bowl, pasta, bacon, spatula\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for 5VnaolWGIy4:  60%|██████    | 3/5 [00:50<00:30, 15.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Adding bacon to pasta | bowl, pasta, bacon, wooden spoon</CONCLUSION>\n",
      "Caption: Adding bacon to pasta | bowl, pasta, bacon, wooden spoon\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is preparing a dish by placing slices of ham onto a baking tray. | pasta, ham, baking tray, hand</CONCLUSION>\n",
      "Caption: The person is preparing a dish by placing slices of ham onto a baking tray. | pasta, ham, baking tray, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Placing slices of ham onto a griddle | hand, ham slices, griddle, cutting board, plastic wrap</CONCLUSION>\n",
      "Caption: Placing slices of ham onto a griddle | hand, ham slices, griddle, cutting board, plastic wrap\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Cooking bacon | Bacon, fork, plate, wooden cutting board, white plate, yellow food item</CONCLUSION>\n",
      "Caption: Cooking bacon | Bacon, fork, plate, wooden cutting board, white plate, yellow food item\n",
      "Window:  ['0350', '0360']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for 5VnaolWGIy4:  80%|████████  | 4/5 [01:08<00:16, 16.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>The bacon is being lifted with tongs from a hot griddle. | Bacon, tongs, griddle, plate, sauce</CONCLUSION>\n",
      "Caption: The bacon is being lifted with tongs from a hot griddle. | Bacon, tongs, griddle, plate, sauce\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Preparing BLT Caesar Pasta Salad | BLT Caesar Pasta Salad, blue bowl, wooden cutting board, pasta, cheese, tomatoes, olives, lettuce, fork, pots, stove</CONCLUSION>\n",
      "Caption: Preparing BLT Caesar Pasta Salad | BLT Caesar Pasta Salad, blue bowl, wooden cutting board, pasta, cheese, tomatoes, olives, lettuce, fork, pots, stove\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Boiling pasta | pot, stove, pasta, bowl, cutting board</CONCLUSION>\n",
      "Caption: Boiling pasta | pot, stove, pasta, bowl, cutting board\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Pouring pasta into boiling water | Blue bowl, pasta, pot, stove, red cups</CONCLUSION>\n",
      "Caption: Pouring pasta into boiling water | Blue bowl, pasta, pot, stove, red cups\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n",
      " addCriterion\n",
      "<CONCLUSION>Boiling pasta | pot, water, pasta, spoon</CONCLUSION>\n",
      "Caption: Boiling pasta | pot, water, pasta, spoon\n",
      "Window:  ['0570', '0580', '0590', '0600', '0610', '0620', '0630', '0640', '0650', '0660']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for 5VnaolWGIy4: 100%|██████████| 5/5 [01:34<00:00, 18.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Cooking pasta | pot, pasta, slotted spoon, bowl, water, stove</CONCLUSION>\n",
      "Caption: Cooking pasta | pot, pasta, slotted spoon, bowl, water, stove\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Stirring pasta salad with a spoon | Bowl, pasta salad, wooden cutting board, green leafy vegetables, hand\\n\\nOutput:\\nStir the pasta salad gently with a spoon until well combined.  \\n<ANSWER>Stir the pasta salad gently with a spoon until well combined.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Adding diced tomatoes to pasta | bowl, pasta, diced tomatoes, red spatula\\n\\nOutput:\\nAdd diced tomatoes to the pasta in the bowl. \\n\\n<ANSWER>Add diced tomatoes to the pasta in the bowl.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Adding bacon to pasta | bowl, pasta, bacon, spatula\\n\\nOutput:\\nAdd bacon to the pasta in the bowl. \\n\\n<ANSWER>Add bacon to the pasta in the bowl.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is preparing a dish by placing slices of ham onto a baking tray. | pasta, ham, baking tray, hand\\n2. Cooking bacon | Bacon, fork, plate, wooden cutting board, white plate, yellow food item\\n\\nOutput:\\nPlace slices of ham on a baking tray and cook bacon separately. \\n\\n<ANSWER>Place ham on a baking tray and cook bacon on a separate pan.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sampled videos:   2%|▏         | 5/210 [10:51<7:22:17, 129.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Preparing BLT Caesar Pasta Salad | BLT Caesar Pasta Salad, blue bowl, wooden cutting board, pasta, cheese, tomatoes, olives, lettuce, fork, pots, stove\\n2. Boiling pasta | pot, water, pasta, spoon\\n\\nOutput:\\nBoil the pasta in salted water until al dente. \\n\\n<ANSWER>Boil the pasta in salted water until al dente.</ANSWER>'}]\n",
      "Processed and updated JSON for video: 5VnaolWGIy4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for wQc0xmPurDc:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is tearing lettuce leaves off a head of romaine lettuce and placing them onto a white plate with a black decorative border. The lettuce leaves are being carefully separated and arranged neatly on the plate. | lettuce, plate, hand</CONCLUSION>\n",
      "Caption: The person is tearing lettuce leaves off a head of romaine lettuce and placing them onto a white plate with a black decorative border. The lettuce leaves are being carefully separated and arranged neatly on the plate. | lettuce, plate, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for wQc0xmPurDc:  25%|██▌       | 1/4 [00:11<00:33, 11.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Pouring salad dressing over lettuce | bowl, lettuce, salad dressing, spoon, plate</CONCLUSION>\n",
      "Caption: Pouring salad dressing over lettuce | bowl, lettuce, salad dressing, spoon, plate\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding ingredients to a bowl | flour, nuts, diced apples, glass bowl, spoon</CONCLUSION>\n",
      "Caption: Adding ingredients to a bowl | flour, nuts, diced apples, glass bowl, spoon\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is preparing a fruit salad by adding various fruits into a bowl and mixing them with a wooden spoon. | Bowl, fruits (grapes, apple chunks), wooden spoon, hands</CONCLUSION>\n",
      "Caption: The person is preparing a fruit salad by adding various fruits into a bowl and mixing them with a wooden spoon. | Bowl, fruits (grapes, apple chunks), wooden spoon, hands\n",
      "Window:  ['0250', '0260', '0270']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for wQc0xmPurDc:  50%|█████     | 2/4 [00:25<00:25, 12.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring salad with wooden spoon | bowl, salad ingredients, wooden spoon, hands</CONCLUSION>\n",
      "Caption: Stirring salad with wooden spoon | bowl, salad ingredients, wooden spoon, hands\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Whisking ingredients together | bowl, flour, whisk, small container, hand</CONCLUSION>\n",
      "Caption: Whisking ingredients together | bowl, flour, whisk, small container, hand\n",
      "Window:  ['0100']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for wQc0xmPurDc:  75%|███████▌  | 3/4 [00:32<00:10, 10.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Adding ingredients to a bowl | bowl, flour, spoon, hand</CONCLUSION>\n",
      "Caption: Adding ingredients to a bowl | bowl, flour, spoon, hand\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for wQc0xmPurDc: 100%|██████████| 4/4 [00:36<00:00,  9.00s/it]\u001b[A\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring flour with a spoon | bowl, flour, spoon</CONCLUSION>\n",
      "Caption: Stirring flour with a spoon | bowl, flour, spoon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is tearing lettuce leaves off a head of romaine lettuce and placing them onto a white plate with a black decorative border. The lettuce leaves are being carefully separated and arranged neatly on the plate. | lettuce, plate, hand\\n2. Pouring salad dressing over lettuce | bowl, lettuce, salad dressing, spoon, plate\\n\\nOutput:\\nAdd salad dressing to the torn romaine lettuce on the plate. \\n\\n<ANSWER>Add salad dressing to the torn romaine lettuce on the plate.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Adding ingredients to a bowl | flour, nuts, diced apples, glass bowl, spoon\\n\\nOutput:\\nMix together the flour, nuts, diced apples, and a splash of water in a bowl using a spoon.\\n\\n<ANSWER>\\nMix the flour, nuts, diced apples, and a splash of water in a bowl with a spoon.  \\n</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Whisking ingredients together | bowl, flour, whisk, small container, hand\\n\\nOutput:\\nWhisk the flour into the mixture until smooth.\\n\\n<ANSWER>\\nWhisk the flour into the mixture until smooth.  \\n</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sampled videos:   3%|▎         | 6/210 [11:32<5:37:35, 99.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Stirring flour with a spoon | bowl, flour, spoon\\n\\nOutput:\\nStir the flour into the bowl using a spoon.  \\n<ANSWER>Stir the flour into the bowl using a spoon.</ANSWER>'}]\n",
      "Processed and updated JSON for video: wQc0xmPurDc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for tKsGWxiWWCg:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is using a spatula to transfer chopped ingredients from a cutting board into a pan. | Cutting board, spatula, chopped ingredients, pan, stove, hand</CONCLUSION>\n",
      "Caption: The person is using a spatula to transfer chopped ingredients from a cutting board into a pan. | Cutting board, spatula, chopped ingredients, pan, stove, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is using a spatula to lift a round, flat food item from a wok filled with chopped ingredients. The food item appears to be a type of pancake or flatbread. The sequence shows the spatula being positioned under the food item, lifted slightly, and then moved to the side. | spatula, hand, round flat food item, wok, chopped ingredients, kitchen counter</CONCLUSION>\n",
      "Caption: The person is using a spatula to lift a round, flat food item from a wok filled with chopped ingredients. The food item appears to be a type of pancake or flatbread. The sequence shows the spatula being positioned under the food item, lifted slightly, and then moved to the side. | spatula, hand, round flat food item, wok, chopped ingredients, kitchen counter\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring food in a wok with a spoon | wok, spoon, food, stove, hand</CONCLUSION>\n",
      "Caption: Stirring food in a wok with a spoon | wok, spoon, food, stove, hand\n",
      "Window:  ['0350', '0360', '0370', '0380', '0390', '0400', '0410', '0420', '0430', '0440']\n",
      " addCriterion\n",
      "<CONCLUSION>Stir-frying rice with vegetables and meat in a wok | wok, spatula, rice, vegetables, meat, wooden spoon, stove, kitchen counter</CONCLUSION>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for tKsGWxiWWCg:  14%|█▍        | 1/7 [00:25<02:34, 25.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: Stir-frying rice with vegetables and meat in a wok | wok, spatula, rice, vegetables, meat, wooden spoon, stove, kitchen counter\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is scooping food from a wok with a spatula and transferring it into a white bowl. | spatula, wok, food, white bowl, hand</CONCLUSION>\n",
      "Caption: The person is scooping food from a wok with a spatula and transferring it into a white bowl. | spatula, wok, food, white bowl, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for tKsGWxiWWCg:  29%|██▊       | 2/7 [00:35<01:20, 16.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring food in a wok with a spoon | wok, spoon, food</CONCLUSION>\n",
      "Caption: Stirring food in a wok with a spoon | wok, spoon, food\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Cracking an egg into a wok containing rice | wok, rice, egg, hand</CONCLUSION>\n",
      "Caption: Cracking an egg into a wok containing rice | wok, rice, egg, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Cracking an egg into a wok containing flour | wok, flour, egg, hand, kitchen counter, stove, window</CONCLUSION>\n",
      "Caption: Cracking an egg into a wok containing flour | wok, flour, egg, hand, kitchen counter, stove, window\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Cracking an egg into a wok containing flour | Wok, flour, egg, hand</CONCLUSION>\n",
      "Caption: Cracking an egg into a wok containing flour | Wok, flour, egg, hand\n",
      "Window:  ['0470', '0480', '0490', '0500']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for tKsGWxiWWCg:  43%|████▎     | 3/7 [00:54<01:09, 17.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring food in a wok with a spatula | wok, spatula, food</CONCLUSION>\n",
      "Caption: Stirring food in a wok with a spatula | wok, spatula, food\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is lifting the lid off a pot containing rice, revealing the contents. | Pot, lid, rice, hand</CONCLUSION>\n",
      "Caption: The person is lifting the lid off a pot containing rice, revealing the contents. | Pot, lid, rice, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Pouring rice into a pot | rice, pot, hand</CONCLUSION>\n",
      "Caption: Pouring rice into a pot | rice, pot, hand\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>Pouring rice into a wok | Rice, wok, hand, container</CONCLUSION>\n",
      "Caption: Pouring rice into a wok | Rice, wok, hand, container\n",
      "Window:  ['0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540', '0550', '0560']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for tKsGWxiWWCg:  57%|█████▋    | 4/7 [01:13<00:54, 18.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Stirring rice with a spoon in a wok | wok, rice, spoon, stove, hand</CONCLUSION>\n",
      "Caption: Stirring rice with a spoon in a wok | wok, rice, spoon, stove, hand\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>Pouring ingredients into a wok | Bowl, spoon, wok, stove, hand</CONCLUSION>\n",
      "Caption: Pouring ingredients into a wok | Bowl, spoon, wok, stove, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for tKsGWxiWWCg:  71%|███████▏  | 5/7 [01:23<00:30, 15.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Pouring liquid into a bowl | Bowl, spoon, stove, wok, hand</CONCLUSION>\n",
      "Caption: Pouring liquid into a bowl | Bowl, spoon, stove, wok, hand\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is chopping meat on a cutting board with a cleaver. The meat is being transferred from the cutting board into a bowl. | cutting board, cleaver, meat, bowl, hand</CONCLUSION>\n",
      "Caption: The person is chopping meat on a cutting board with a cleaver. The meat is being transferred from the cutting board into a bowl. | cutting board, cleaver, meat, bowl, hand\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is chopping vegetables on a cutting board with a cleaver. The sequence shows the process of transferring chopped vegetables into a bowl. | cutting board, cleaver, bowl, vegetables, person's hands</CONCLUSION>\n",
      "Caption: The person is chopping vegetables on a cutting board with a cleaver. The sequence shows the process of transferring chopped vegetables into a bowl. | cutting board, cleaver, bowl, vegetables, person's hands\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for tKsGWxiWWCg:  86%|████████▌ | 6/7 [01:42<00:16, 16.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>The person is cutting a piece of food with a knife on a wooden board. | knife, wooden board, food, hand, bowl, wok, bottles, stove, countertop</CONCLUSION>\n",
      "Caption: The person is cutting a piece of food with a knife on a wooden board. | knife, wooden board, food, hand, bowl, wok, bottles, stove, countertop\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is cutting meat with a cleaver on a wooden cutting board. | Meat, cleaver, cutting board, bowls, sauce bottles, stove, wok, green onions.</CONCLUSION>\n",
      "Caption: The person is cutting meat with a cleaver on a wooden cutting board. | Meat, cleaver, cutting board, bowls, sauce bottles, stove, wok, green onions.\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is cutting meat with a cleaver on a wooden board. | Meat, cleaver, wooden board, bowl, green onions, wok, stove, salt shaker, soy sauce bottle, other kitchen items</CONCLUSION>\n",
      "Caption: The person is cutting meat with a cleaver on a wooden board. | Meat, cleaver, wooden board, bowl, green onions, wok, stove, salt shaker, soy sauce bottle, other kitchen items\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for tKsGWxiWWCg: 100%|██████████| 7/7 [01:59<00:00, 17.02s/it]\u001b[A\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Chopping meat with a knife | cutting board, knife, bowl, meat, hand</CONCLUSION>\n",
      "Caption: Chopping meat with a knife | cutting board, knife, bowl, meat, hand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is using a spatula to transfer chopped ingredients from a cutting board into a pan. | Cutting board, spatula, chopped ingredients, pan, stove, hand\\n2. Stirring food in a wok with a spoon | wok, spoon, food, stove, hand\\n\\nOutput:\\nStir the food in the wok continuously over medium heat.  \\n<ANSWER>Stir the food in the wok continuously over medium heat.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is scooping food from a wok with a spatula and transferring it into a white bowl. | spatula, wok, food, white bowl, hand\\n\\nOutput:\\nScoop food from the wok using a spatula and transfer it to the white bowl.  \\n<ANSWER>Scoop food from the wok with a spatula and place it into the white bowl.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Cracking an egg into a wok containing rice | wok, rice, egg, hand\\n2. Stirring food in a wok with a spatula | wok, spatula, food\\n\\nOutput:\\nStir the egg and rice in the wok continuously until cooked. \\n\\n<ANSWER>Stir the egg and rice in the wok continuously until cooked.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is lifting the lid off a pot containing rice, revealing the contents. | Pot, lid, rice, hand\\n\\nOutput:\\nRemove the lid from the pot to check the rice. \\n\\n<ANSWER>Remove the lid from the pot to check the rice.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. Pouring ingredients into a wok | Bowl, spoon, wok, stove, hand\\n\\nOutput:\\nAdd the ingredients to the hot wok.  \\n<ANSWER>Add the ingredients to the hot wok.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is chopping meat on a cutting board with a cleaver. The meat is being transferred from the cutting board into a bowl. | cutting board, cleaver, meat, bowl, hand\\n\\nOutput:\\nChop the meat using a cleaver on a cutting board, then transfer it to a bowl.  \\n<ANSWER>Chop the meat with a cleaver on a cutting board and transfer it to a bowl.</ANSWER>'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sampled videos:   3%|▎         | 7/210 [13:39<6:07:01, 108.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'You are given multiple captions from a short cooking clip, in chronological order. Write ONE concise sentence that is both short, and instructional. Use an imperative tone, as if giving instructions for cooking or performing a task. Your response MUST be enclosed between <ANSWER> and </ANSWER>, containing ONLY the final instruction sentence.1. The person is cutting meat with a cleaver on a wooden cutting board. | Meat, cleaver, cutting board, bowls, sauce bottles, stove, wok, green onions.\\n\\nOutput:\\nCut the meat into even pieces using a cleaver on a wooden board. \\n\\n<ANSWER>Cut the meat into even pieces using a cleaver on a wooden board.</ANSWER>'}]\n",
      "Processed and updated JSON for video: tKsGWxiWWCg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for T_fPNAK5Ecg:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is transferring sausages from a frying pan onto a plate. | frying pan, sausages, plate, hand, knife</CONCLUSION>\n",
      "Caption: The person is transferring sausages from a frying pan onto a plate. | frying pan, sausages, plate, hand, knife\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is transferring sausages from a pan to a plate. | sausages, pan, plate, hand, knife</CONCLUSION>\n",
      "Caption: The person is transferring sausages from a pan to a plate. | sausages, pan, plate, hand, knife\n",
      "Window:  ['0250', '0260', '0270', '0280', '0290', '0300', '0310', '0320', '0330', '0340']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is placing a cookie on a plate. | plate, cookie, hand</CONCLUSION>\n",
      "Caption: The person is placing a cookie on a plate. | plate, cookie, hand\n",
      "Window:  ['0350', '0360', '0370', '0380', '0390', '0400', '0410', '0420', '0430', '0440']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is preparing food on a plate. They start with a plate containing sausages and then add mashed potatoes using a spoon. The sequence shows the gradual addition of mashed potatoes around the sausages. | Plate, sausages, mashed potatoes, spoon, hand</CONCLUSION>\n",
      "Caption: The person is preparing food on a plate. They start with a plate containing sausages and then add mashed potatoes using a spoon. The sequence shows the gradual addition of mashed potatoes around the sausages. | Plate, sausages, mashed potatoes, spoon, hand\n",
      "Window:  ['0450', '0460', '0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is scooping mashed potatoes onto a plate with sausages. | Plate, sausages, mashed potatoes, hand, spoon, knife, napkin</CONCLUSION>\n",
      "Caption: The person is scooping mashed potatoes onto a plate with sausages. | Plate, sausages, mashed potatoes, hand, spoon, knife, napkin\n",
      "Window:  ['0600', '0610', '0620', '0630', '0640', '0650', '0660', '0670', '0680', '0690']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is serving a creamy dish onto a plate with sausages. | Creamy dish, sausages, wooden spoon, plate, table, pot, butter packet, knife.</CONCLUSION>\n",
      "Caption: The person is serving a creamy dish onto a plate with sausages. | Creamy dish, sausages, wooden spoon, plate, table, pot, butter packet, knife.\n",
      "Window:  ['0820', '0830', '0840', '0850', '0860', '0870', '0880', '0890', '0900', '0910']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing scenes for T_fPNAK5Ecg:  17%|█▋        | 1/6 [00:40<03:22, 40.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " addCriterion\n",
      "<CONCLUSION>Pouring mashed potatoes onto a plate with sausages | Plate, mashed potatoes, sausages, knife, butter packet</CONCLUSION>\n",
      "Caption: Pouring mashed potatoes onto a plate with sausages | Plate, mashed potatoes, sausages, knife, butter packet\n",
      "Window:  ['0000', '0010', '0020', '0030', '0040', '0050', '0060', '0070', '0080', '0090']\n",
      " addCriterion\n",
      "<CONCLUSION>The person is cutting a block of cheese with a knife. The cheese is then placed into a pot of rice. | Cheese, knife, pot, rice</CONCLUSION>\n",
      "Caption: The person is cutting a block of cheese with a knife. The cheese is then placed into a pot of rice. | Cheese, knife, pot, rice\n",
      "Window:  ['0100', '0110', '0120', '0130', '0140', '0150', '0160', '0170', '0180', '0190']\n",
      " addCriterion\n",
      "<CONCLUSION>Person adds salt to rice | Salt, rice, pot, stove, hand</CONCLUSION>\n",
      "Caption: Person adds salt to rice | Salt, rice, pot, stove, hand\n",
      "Window:  ['0200', '0210', '0220', '0230', '0240', '0250', '0260', '0270', '0280', '0290']\n",
      " addCriterion\n",
      "<CONCLUSION>Adding butter to rice | Butter, rice, pot, stove, hand</CONCLUSION>\n",
      "Caption: Adding butter to rice | Butter, rice, pot, stove, hand\n",
      "Window:  ['0350', '0360', '0370', '0380', '0390', '0400', '0410', '0420', '0430', '0440']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring mashed potatoes with a spoon | pot, spoon, hand, mashed potatoes</CONCLUSION>\n",
      "Caption: Stirring mashed potatoes with a spoon | pot, spoon, hand, mashed potatoes\n",
      "Window:  ['0450', '0460', '0470', '0480', '0490', '0500', '0510', '0520', '0530', '0540']\n",
      " addCriterion\n",
      "<CONCLUSION>Stirring mashed potatoes with a hand mixer | stainless steel pot, hand mixer, mashed potatoes, person's hands</CONCLUSION>\n",
      "Caption: Stirring mashed potatoes with a hand mixer | stainless steel pot, hand mixer, mashed potatoes, person's hands\n",
      "Window:  ['0600', '0610', '0620', '0630', '0640', '0650', '0660', '0670', '0680', '0690']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing scenes for T_fPNAK5Ecg:  17%|█▋        | 1/6 [01:09<05:48, 69.67s/it]\n",
      "Processing sampled videos:   3%|▎         | 7/210 [14:49<7:10:00, 127.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampled_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampled_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mannotations_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mannotations_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43maggregator\u001b[49m\u001b[43m=\u001b[49m\u001b[43maggregator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprocessor0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessor0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCOT_MODEL_ID\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCOT_MODEL_ID\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 171\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(base_folder, sampled_file, output_folder, annotations_file, aggregator, processor0, model0, COT_MODEL_ID)\u001b[39m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Scene captions\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m video_result = \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvideo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOT_MODEL_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m    174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# Aggregation\u001b[39;00m\n\u001b[32m    177\u001b[39m aggregated_scenes = {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mprocess_video\u001b[39m\u001b[34m(video_id, video_folder, processor, model, model_id, window_size, base_stride, similarity_threshold, frame_frequency)\u001b[39m\n\u001b[32m     99\u001b[39m output = {video_id: {}}\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m scene_folder \u001b[38;5;129;01min\u001b[39;00m tqdm(scenes, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing scenes for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     scene_id, captions = \u001b[43mprocess_scene\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscene_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_stride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_frequency\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     output[video_id][scene_id] = captions\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mprocess_scene\u001b[39m\u001b[34m(scene_folder, video_folder, processor, model, model_id, window_size, base_stride, similarity_threshold, frame_frequency)\u001b[39m\n\u001b[32m     81\u001b[39m frame_numbers = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m frame_numbers]\n\u001b[32m     83\u001b[39m sampled_frames = adaptive_frame_sampling(frame_numbers, base_stride, frame_frequency)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m captions = \u001b[43msliding_window_captioning_dynamic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscene_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_stride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43msimilarity_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43msimilarity_threshold\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m scene_id = scene_folder.split(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m1\u001b[39m]\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m scene_id, captions\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36msliding_window_captioning_dynamic\u001b[39m\u001b[34m(folder_path, frame_numbers, processor, model, model_id, window_size, base_stride, similarity_threshold)\u001b[39m\n\u001b[32m     42\u001b[39m window = frame_numbers[idx:\u001b[38;5;28mmin\u001b[39m(idx + window_size, n_frames)]\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWindow: \u001b[39m\u001b[33m\"\u001b[39m, window)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m caption = \u001b[43mMMCoT\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze_sequence_by_indexes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprocessor0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCaption:\u001b[39m\u001b[33m\"\u001b[39m, caption)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m caption \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(caption).strip().lower() == \u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/scene_captioner/LLaMACoT/MMCoT.py:199\u001b[39m, in \u001b[36manalyze_sequence_by_indexes\u001b[39m\u001b[34m(folder, frame_indexes, processor, model, device, max_new_tokens)\u001b[39m\n\u001b[32m    196\u001b[39m messages = create_message(multi_image_input, num_images=\u001b[38;5;28mlen\u001b[39m(images_to_concat))\n\u001b[32m    197\u001b[39m inputs = process_inputs(processor, messages, device)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m conclusion = \u001b[43mgenerate_conclusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# Free memory\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m images_to_concat, multi_image_input, inputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/scene_captioner/LLaMACoT/MMCoT.py:168\u001b[39m, in \u001b[36mgenerate_conclusion\u001b[39m\u001b[34m(processor, model, inputs, max_new_tokens)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[33;03mGenerate text, decoding only the new tokens without including the input.\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# decode only generated tokens\u001b[39;00m\n\u001b[32m    177\u001b[39m generated_text = processor.batch_decode(\n\u001b[32m    178\u001b[39m     outputs.sequences[:, inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m1\u001b[39m]:],  \u001b[38;5;66;03m# slice after prompt\u001b[39;00m\n\u001b[32m    179\u001b[39m     skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    180\u001b[39m )[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:2629\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2621\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2622\u001b[39m         input_ids=input_ids,\n\u001b[32m   2623\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2624\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2625\u001b[39m         **model_kwargs,\n\u001b[32m   2626\u001b[39m     )\n\u001b[32m   2628\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2640\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2641\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2642\u001b[39m         input_ids=input_ids,\n\u001b[32m   2643\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2644\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2645\u001b[39m         **model_kwargs,\n\u001b[32m   2646\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:3613\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3611\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3612\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3613\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3615\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3616\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3617\u001b[39m     outputs,\n\u001b[32m   3618\u001b[39m     model_kwargs,\n\u001b[32m   3619\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3620\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:959\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    957\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    958\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    961\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1493\u001b[39m, in \u001b[36mQwen2_5_VLForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas, cache_position, second_per_grid_ts, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m   1488\u001b[39m output_attentions = output_attentions \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_attentions\n\u001b[32m   1489\u001b[39m output_hidden_states = (\n\u001b[32m   1490\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m   1491\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpixel_values_videos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel_values_videos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_grid_thw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_grid_thw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvideo_grid_thw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvideo_grid_thw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m    \u001b[49m\u001b[43msecond_per_grid_ts\u001b[49m\u001b[43m=\u001b[49m\u001b[43msecond_per_grid_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1510\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1512\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1514\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1323\u001b[39m, in \u001b[36mQwen2_5_VLModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas, cache_position, second_per_grid_ts, **kwargs)\u001b[39m\n\u001b[32m   1320\u001b[39m         delta = delta.repeat_interleave(batch_size // delta.shape[\u001b[32m0\u001b[39m], dim=\u001b[32m1\u001b[39m)\n\u001b[32m   1321\u001b[39m         position_ids += delta.to(position_ids.device)\n\u001b[32m-> \u001b[39m\u001b[32m1323\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlanguage_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1337\u001b[39m output = Qwen2_5_VLModelOutputWithPast(\n\u001b[32m   1338\u001b[39m     last_hidden_state=outputs.last_hidden_state,\n\u001b[32m   1339\u001b[39m     past_key_values=outputs.past_key_values,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1342\u001b[39m     rope_deltas=\u001b[38;5;28mself\u001b[39m.rope_deltas,\n\u001b[32m   1343\u001b[39m )\n\u001b[32m   1344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;28;01melse\u001b[39;00m output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:914\u001b[39m, in \u001b[36mQwen2_5_VLTextModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **kwargs)\u001b[39m\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    912\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_position_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:765\u001b[39m, in \u001b[36mQwen2_5_VLDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    762\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    764\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    776\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    778\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:705\u001b[39m, in \u001b[36mQwen2_5_VLAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    691\u001b[39m attn_output, attn_weights = attention_interface(\n\u001b[32m    692\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    693\u001b[39m     query_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    701\u001b[39m     **kwargs,\n\u001b[32m    702\u001b[39m )\n\u001b[32m    704\u001b[39m attn_output = attn_output.reshape(bsz, q_len, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m attn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.linear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1927\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1922\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[32m   1926\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Union[Tensor, \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1928\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1929\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "run_pipeline(\n",
    "    base_folder=base_folder,\n",
    "    sampled_file=sampled_file,\n",
    "    output_folder=output_folder,\n",
    "    annotations_file=annotations_file,\n",
    "    aggregator=aggregator,\n",
    "    processor0=processor0,\n",
    "    model0=model0,\n",
    "    COT_MODEL_ID=COT_MODEL_ID\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
