{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488e3ab8-2aaa-4ec8-b8a5-16dd84761cb7",
   "metadata": {},
   "source": [
    "## Storage:\n",
    "This code allows the various packages and installations to be downloaded on the network volume instead of the disk, avoiding any disk storage issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e1cb6a-21b8-4b46-b3c3-b6d27c1b64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/workspace/hf'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/workspace/hf/transformers'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/workspace/hf/datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd1e79-7aca-4a99-90cc-46170e3a29d0",
   "metadata": {},
   "source": [
    "## Manual Installations:\n",
    "Installing dependencies in the case of not having a requirements.txt (will change later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a844d74b-0aa2-48bd-9624-3a0cec9ea6f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Uninstalling potential conflicts...\n",
      "Found existing installation: torch 2.8.0.dev20250319+cu128\n",
      "Uninstalling torch-2.8.0.dev20250319+cu128:\n",
      "  Successfully uninstalled torch-2.8.0.dev20250319+cu128\n",
      "Found existing installation: torchvision 0.22.0.dev20250319+cu128\n",
      "Uninstalling torchvision-0.22.0.dev20250319+cu128:\n",
      "  Successfully uninstalled torchvision-0.22.0.dev20250319+cu128\n",
      "Found existing installation: torchaudio 2.6.0.dev20250319+cu128\n",
      "Uninstalling torchaudio-2.6.0.dev20250319+cu128:\n",
      "  Successfully uninstalled torchaudio-2.6.0.dev20250319+cu128\n",
      "\u001b[33mWARNING: Skipping flash-attn as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: transformers 4.55.0\n",
      "Uninstalling transformers-4.55.0:\n",
      "  Successfully uninstalled transformers-4.55.0\n",
      "\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping nvidia-pyindex as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping nvidia-pip as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m>>> Upgrading pip...\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m>>> Manually installing opencv and accelerate\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.7)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch>=2.0.0->accelerate)\n",
      "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch>=2.0.0->accelerate) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m267.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m337.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m291.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m252.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m313.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m424.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m224.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m415.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m363.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m406.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m355.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m406.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m401.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m266.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, accelerate\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.6.3\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.6.3:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.8.55━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.8.55:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.8.55━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.8.61\u001b[0m \u001b[32m 1/17\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.8.61:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.61━━\u001b[0m \u001b[32m 1/17\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.25.1━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.25.1:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.25.1━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.55━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.55:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.55━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufile-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufile-cu12 1.13.0.11━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufile-cu12-1.13.0.11:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufile-cu12-1.13.0.11━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.8.57m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.8.57:━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.57[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.61[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.61:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.61━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.8.57[0m \u001b[32m 8/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.8.57:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.57━\u001b[0m \u001b[32m 8/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.3.14━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.3.14:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.3.14━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.7.53[0m \u001b[32m10/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.7.53:━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.7.53━━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.41━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.41:90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.41━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.8.0.87━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.8.0.87:0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.8.0.87━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1291m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.2.55[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.2.55:\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.2.55━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [accelerate]7\u001b[0m [accelerate]lver-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.10.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 torch-2.8.0 triton-3.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m>>> Installing PyTorch 2.3.1 + CUDA 12.1...\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.3.1+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp311-cp311-linux_x86_64.whl (781.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.0/781.0 MB\u001b[0m \u001b[31m362.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.18.1+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m392.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.3.1+cu121\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m403.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1+cu121) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m318.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m174.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m311.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m320.2 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m327.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m488.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m397.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m536.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m509.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m349.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.3.1 (from torch==2.3.1+cu121)\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m497.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.1+cu121) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.1+cu121) (11.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1+cu121) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.1+cu121) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.1+cu121) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.4.0\n",
      "\u001b[2K    Uninstalling triton-3.4.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.4.0\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━\u001b[0m \u001b[32m 0/15\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.8.9015\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.8.90:━━\u001b[0m \u001b[32m 0/15\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.8.900/15\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━\u001b[0m \u001b[32m 0/15\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.27.3/15\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.27.3:━━━\u001b[0m \u001b[32m 0/15\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.27.3 0/15\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.8.93[0m \u001b[32m 2/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93━\u001b[0m \u001b[32m 2/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.90━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.90:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.90━━━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.83━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.83:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90m \u001b[32m 5/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:━━━━━━━━━━━━\u001b[0m \u001b[32m 5/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90[0m \u001b[32m 5/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93[0m \u001b[32m 6/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93━\u001b[0m \u001b[32m 6/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90━\u001b[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.4.1━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.4.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu120m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.3.90━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.3.90:m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu121m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.10.2.21━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.10.2.21:[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21━━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.8.0[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.8.0:━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]nn-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.8.00m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [torchaudio]5\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.1+cu121 torchaudio-2.3.1+cu121 torchvision-0.18.1+cu121 triton-2.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m>>> Installing latest Transformers + Accelerate...\n",
      "Collecting transformers==4.46.3\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting accelerate==1.0.1\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.3)\n",
      "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.0.1) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.0.1) (2.3.1+cu121)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (1.1.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==1.0.1) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==1.0.1) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==1.0.1) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate==1.0.1) (1.3.0)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m249.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m239.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers, accelerate\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.4\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.4:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.4\n",
      "\u001b[2K  Attempting uninstall: acceleratem\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: accelerate 1.10.0━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling accelerate-1.10.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled accelerate-1.10.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [accelerate]3\u001b[0m [accelerate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.0.1 tokenizers-0.20.3 transformers-4.46.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m>>> Installing other dependencies...\n",
      "Requirement already satisfied: decord in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
      "Collecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from decord) (2.1.2)\n",
      "Collecting future (from ffmpeg-python)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio) (11.0.0)\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Installing collected packages: imageio, future, ffmpeg-python\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [ffmpeg-python]0m [future]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ffmpeg-python-0.2.0 future-1.0.0 imageio-2.37.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m>>> Setting CUDA environment variables...\n",
      "/bin/bash: -c: line 1: unexpected EOF while looking for matching `\"'\n",
      "/bin/bash: -c: line 2: syntax error: unexpected end of file\n"
     ]
    }
   ],
   "source": [
    "!echo \">>> Uninstalling potential conflicts...\"\n",
    "!pip uninstall -y torch torchvision torchaudio flash-attn transformers accelerate nvidia-pyindex nvidia-pip || true\n",
    "\n",
    "!echo \">>> Upgrading pip...\"\n",
    "!pip install --upgrade pip\n",
    "\n",
    "!echo \">>> Manually installing opencv and accelerate\"\n",
    "!pip install opencv-python\n",
    "!pip install accelerate\n",
    "\n",
    "!echo \">>> Installing PyTorch 2.3.1 + CUDA 12.1...\"\n",
    "!pip install torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "!echo \">>> Installing latest Transformers + Accelerate...\"\n",
    "!pip install transformers==4.46.3 accelerate==1.0.1\n",
    "\n",
    "!echo \">>> Installing other dependencies...\"\n",
    "!pip install decord ffmpeg-python imageio opencv-python\n",
    "\n",
    "!echo \">>> Setting CUDA environment variables...\"\n",
    "!export CUDA_HOME=/usr/local/cuda-12.1\n",
    "!export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH\n",
    "\n",
    "!echo \">>> Setup Complete!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f4587f-34e2-4d25-8339-e1e482dcb512",
   "metadata": {},
   "source": [
    "## Setting Up and Loading the Model\n",
    "Here, we import all the necessary packages, use the setup() function and then load the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a7f865-9949-400f-b3c4-c5a1a0a92faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading VideoLLaMA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/DAMO-NLP-SG/VideoLLaMA3-7B:\n",
      "- configuration_videollama3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/DAMO-NLP-SG/VideoLLaMA3-7B:\n",
      "- modeling_videollama3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7172dd2584c94a859491cf4d166911b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e739c39aa54ded8ad33ab00a71fdfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/DAMO-NLP-SG/VideoLLaMA3-7B:\n",
      "- processing_videollama3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from typing import List\n",
    "import cv2  # For frame extraction\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "import torch\n",
    "\n",
    "\n",
    "def setup(repo_url: str = \"https://github.com/DAMO-NLP-SG/VideoLLaMA3.git\", repo_dir: str = \"VideoLLaMA3\"):\n",
    "    \"\"\"\n",
    "    Sets up the environment by cloning the model repository and installing dependencies.\n",
    "    Only installs requirements if needed, and defaults to known dependencies if \n",
    "    requirements.txt is missing.\n",
    "    \"\"\"\n",
    "    # Checking if the repo already exists or not\n",
    "    if not os.path.exists(repo_dir):\n",
    "        print(f\"[INFO] Cloning repository {repo_url}...\")\n",
    "        subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
    "    else:\n",
    "        print(f\"[INFO] Repository '{repo_dir}' already exists. Skipping clone.\")\n",
    "\n",
    "    # Checks if a requirements.txt is present in the folder\n",
    "    #   - may have to change this if requirements.txt is in another folder/has another path\n",
    "    req_path = \"requirements.txt\"\n",
    "    if os.path.exists(req_path):\n",
    "        print(f\"[INFO] Found requirements.txt at {req_path}. Installing...\")\n",
    "        subprocess.run([\"pip\", \"install\", \"-r\", req_path], check=True)\n",
    "    else:\n",
    "        # the default dependencies mentioned here are the dependencies commented out below\n",
    "        # this can be sorted out further once we have a unified requirements.txt\n",
    "        print(f\"[INFO] No requirements.txt found. Using default dependencies.\")\n",
    "\n",
    "# we run the setup and make the model global\n",
    "print(\"[INFO] Loading VideoLLaMA model...\")\n",
    "MODEL_NAME = \"DAMO-NLP-SG/VideoLLaMA3-7B\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    offload_folder=\"offload\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "print(\"[INFO] Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c17122-fd39-4b28-bee1-a20b49ae4c75",
   "metadata": {},
   "source": [
    "# Functions for generating captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec29ed-02a3-48a4-9ced-3e603ff532c8",
   "metadata": {},
   "source": [
    "## generate_caption\n",
    "This function takes in one or more images in the array *images* and a given prompt *prmopt*, and will prompt the model with the inputs and prompt and return the \"caption\" that the model generates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32d1ebb1-b466-420d-9020-ada2b2828720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_caption(images: List[str], prompt: str, tokens = 40) -> str:\n",
    "    \"\"\"\n",
    "    Generates a caption for one or more images given a text prompt.\n",
    "\n",
    "    :param images: List of image file paths.\n",
    "    :param prompt: Text prompt to guide the caption generation.\n",
    "    :return: Generated caption as a string.\n",
    "    \"\"\"\n",
    "    #print(f\"[INFO] Generating caption for {len(images)} image(s)...\")\n",
    "    conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            *[{\"type\": \"image\", \"image\": {\"image_path\": img}} for img in images],\n",
    "            {\"type\": \"text\", \"text\": prompt}\n",
    "        ]\n",
    "    },\n",
    "    ]\n",
    "    inputs = processor(\n",
    "        conversation=conversation,\n",
    "        add_system_prompt=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "    if \"pixel_values\" in inputs:\n",
    "      inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(torch.float16)\n",
    "    with torch.inference_mode():\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=tokens)\n",
    "    caption = processor.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebead937-531d-403f-8165-3d1a994924d0",
   "metadata": {},
   "source": [
    "## extract_frames\n",
    "This will extract a frame every *frame_interval* frames and stores this collection of frames in *output_dir*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e361825e-be1a-4a14-a0bd-d1bfb43faaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def extract_frames(video_path: str, output_dir: str, frame_interval: int = 120) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts frames from a video at a specified interval.\n",
    "\n",
    "    :param video_path: Path to the input video.\n",
    "    :param output_dir: Directory where extracted frames will be saved.\n",
    "    :param frame_interval: Save every `frame_interval` frames (default: 120).\n",
    "    :return: List of file paths to extracted frames.\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Extracting frames from {video_path} every {frame_interval} frames...\")\n",
    "\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "        \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count, saved = 0, 0\n",
    "    frame_paths = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % frame_interval == 0:\n",
    "            frame_filename = os.path.join(output_dir, f\"frame_{saved:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            frame_paths.append(frame_filename)\n",
    "            saved += 1\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"[INFO] Extracted {len(frame_paths)} frames.\")\n",
    "    return frame_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2abe32-5306-4acf-a7c0-82984decff69",
   "metadata": {},
   "source": [
    "## generate_video_caption\n",
    "This function will extract the necessary frames from the video sent in as input and take the captions from each frame, and merge them to be a coherent summary of the entire video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff08657-5313-4f5a-a4a2-b5a1a8e3f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_video_caption(video_path: str, frames) -> str:\n",
    "    \"\"\"\n",
    "    Combines frame-wise captions into a single, coherent video-level caption.\n",
    "\n",
    "    :param video_path: file path for the video we are working with\n",
    "    :return: Final video caption string.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Generating video-level caption...\")\n",
    "    output_dir = f\"{video_path}_frames\"\n",
    "    frames = extract_frames(video_path, output_dir, frames)\n",
    "    frame_captions = [generate_caption([frame], \"You are given a single frame extracted from a video. Generate a detailed and contextually rich caption that describes not only what is visually present (objects, people, setting, actions, emotions) but also infers the likely context of the scene based on visual cues such as lighting, expressions, clothing, or background elements. If the frame seems to be part of an ongoing action or event, include your best guess at what is happening before and after this moment, using natural language to provide a cohesive narrative. Be concise but descriptive, and focus on making the caption feel like a natural description someone might give while watching the video. Limit 32 tokens\") for frame in frames]\n",
    "\n",
    "    # Use the model to merge frame captions into a coherent summary\n",
    "    merged_prompt = \" \".join(frame_captions)\n",
    "    summary_input = f\"In 256 tokens or less, merge these captions into one continuous, coherent, and natural-sounding description of the entire video. Avoid repeating the same details unless necessary, ensure smooth transitions between actions, and infer the overall context or story from the captions. If possible, describe the progression of events as if narrating the video from start to finish: {merged_prompt}\\n Less than 256 tokens!\"\n",
    "    final_caption = generate_caption([], summary_input, 260)\n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b4a27-25b4-4a77-9bf8-4b4acad563f5",
   "metadata": {},
   "source": [
    "## generate_video_auto\n",
    "This function will extract the necessary frames from the video sent in as input and builds the final caption autoregressively, using the formerly created captions and images as input for each successive frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b31e19a-4da1-4642-a3b2-13e4bafb0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoregressive_prompt(generated_captions: list[str]) -> str:\n",
    "    prompt = \"You are an expert video captioning assistant. Here are the captions generated so far:\\n\\n\"\n",
    "    for i, cap in enumerate(generated_captions):\n",
    "        prompt += f\"Frame {i+1}: {cap.strip()}\\n\"\n",
    "    prompt += f\"\\nNow describe Frame {len(generated_captions) + 1} in a way that is consistent with previous frames and captures the visual content accurately.\\n\"\n",
    "    prompt += f\"Frame {len(generated_captions) + 1}:\"\n",
    "    return prompt\n",
    "\n",
    "def build_video_summary_prompt(generated_captions: list[str]) -> str:\n",
    "    prompt = (\n",
    "        \"You are a professional film narrator tasked with summarizing a video based on frame-by-frame descriptions.\\n\\n\"\n",
    "        \"Below is a list of captions generated from individual frames of the video. Use these to infer the setting, environment, and the sequence of events.\\n\\n\"\n",
    "        \"Your task is to write a single, vivid, and coherent description that captures:\\n\"\n",
    "        \"- The environment and setting of the video\\n\"\n",
    "        \"- The sequence of actions and events\\n\"\n",
    "        \"- The overall mood, atmosphere, or intent behind the scene\\n\\n\"\n",
    "        \"Avoid repeating the frame captions verbatim. Instead, synthesize the information into a fluid, descriptive paragraph as if narrating the video to someone who cannot see it.\\n\\n\"\n",
    "        \"Frame Captions:\\n\"\n",
    "    )\n",
    "    for i, caption in enumerate(generated_captions):\n",
    "        prompt += f\"Frame {i+1}: {caption.strip()}\\n\"\n",
    "    prompt += \"\\nFinal Video Caption:\"\n",
    "    return generate_caption([], prompt, 512)\n",
    "\n",
    "def generate_video_auto(video_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Autoregressively creates a caption for an entire video\n",
    "\n",
    "    :param video_path: file path for the video we are working with\n",
    "    :return: Final video caption string\n",
    "    \"\"\"\n",
    "\n",
    "    generated_captions = []\n",
    "    print(\"[INFO] Generating video-level caption...\")\n",
    "    output_dir = f\"{video_path}_frames\"\n",
    "    frames = extract_frames(video_path, output_dir)\n",
    "    for frame in frames:\n",
    "        prompt = build_autoregressive_prompt(generated_captions)\n",
    "        caption = generate_caption([frame], prompt)\n",
    "        generated_captions.append(caption)\n",
    "\n",
    "    return build_video_summary_prompt(generated_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56025b11-81b7-4f66-88ea-6e8117708c30",
   "metadata": {},
   "source": [
    "## generate_k_slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f139a15-a938-489a-84e6-7674abce4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_k_slides(frames, window_size = 3, jump = 1):\n",
    "    \"\"\"\n",
    "    A function that will perform the k-frames sliding window processing \n",
    "\n",
    "    :param frames - the extracted frames from the extract_frames() function\n",
    "    :param window_size - the size of the window we are working with\n",
    "    :param jump - how much we \"jump\" by in the sliding window\n",
    "    :return something to send to CMMCoT??? (based on the daigram), not sure what this means\n",
    "    \"\"\"\n",
    "\n",
    "    # one functionality of a function like this could simply be to generate the windows themselves\n",
    "    k_windows = []\n",
    "    for i in range(0, len(frames) - window_size + 1, jump):\n",
    "        window_frames = frames[i:i + window_size]\n",
    "        k_windows.append(window_frames)\n",
    "\n",
    "    # return k_windows\n",
    "\n",
    "    # we could also then use these windows to prompt the model\n",
    "    scene = \"\"\n",
    "    for i, window in enumerate(k_windows):\n",
    "        prompt = f\"\"\"\n",
    "        Current scene context so far:\n",
    "        {scene}\n",
    "\n",
    "        New K-frame snippet {i + 1}\n",
    "        (frames attached)\n",
    "\n",
    "        Update the scene description, adding only new information with a strict limit of 60 tokens\n",
    "        \"\"\"\n",
    "        scene = scene + \"\\n\" + generate_caption(window, prompt, 64)\n",
    "\n",
    "    # after the last window\n",
    "    final_prompt = f\"\"\"\n",
    "    Here is the accumulated scene description:\n",
    "    {scene}\n",
    "\n",
    "    Write a single, coherent narrative-style caption summarizing the entire scene\n",
    "    \"\"\"\n",
    "\n",
    "    return generate_caption([], final_prompt, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe596a-b3e2-494e-b84d-6a82cf370266",
   "metadata": {},
   "source": [
    "# Testing Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2dc5d-351e-418c-8a12-0be049b817f2",
   "metadata": {},
   "source": [
    "## Testing With Videos from /VideoLLaMA3/assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52fe4edb-b4ca-4a0e-a5c5-700ac36029e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_video_caption() missing 1 required positional argument: 'frames'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_video_caption\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/workspace/video_LLama3/VideoLLaMA3/assets/cat_and_chicken.mp4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: generate_video_caption() missing 1 required positional argument: 'frames'"
     ]
    }
   ],
   "source": [
    "print(generate_video_caption(\"/workspace/video_LLama3/VideoLLaMA3/assets/cat_and_chicken.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf069d-0565-46c9-87ef-1306ec1b7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_video_auto(\"/workspace/video_LLama3/VideoLLaMA3/assets/cat_and_chicken.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08484eac-7d62-4636-8e33-e22de784a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = extract_frames(\"/workspace/video_LLama3/headphones.mp4\", \"workspace/video_LLama3/headphones.mp4_frames\", 10)\n",
    "caption = generate_k_slides(frames)\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877ea3a-6396-40da-b364-1d71a7186247",
   "metadata": {},
   "source": [
    "## Testing with COIN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1aae8-e63f-4845-b71f-f9c85914a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root_path = Path(\"/workspace/video_LLama3/coin_sample_videos\")\n",
    "for subfolder in root_path.iterdir():\n",
    "    if subfolder.is_dir():\n",
    "        for video in subfolder.glob(\"*.mp4\"):\n",
    "            print(f\"{video} Caption:\")\n",
    "            print(f\"https://www.youtube.com/embed/{video.stem}\")\n",
    "            print(generate_video_caption(str(video), 60))\n",
    "            print(\"---------------------------------------------------\")\n",
    "    else:\n",
    "        print(\"Videos not downloaded correctly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
